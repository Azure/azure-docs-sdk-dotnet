<Type Name="PropertyId" FullName="Microsoft.CognitiveServices.Speech.PropertyId">
  <TypeSignature Language="C#" Value="public enum PropertyId" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed PropertyId extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:Microsoft.CognitiveServices.Speech.PropertyId" />
  <TypeSignature Language="VB.NET" Value="Public Enum PropertyId" />
  <TypeSignature Language="F#" Value="type PropertyId = " />
  <AssemblyInfo>
    <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
    <AssemblyVersion>1.16.0.28</AssemblyVersion>
    <AssemblyVersion>1.17.0.28</AssemblyVersion>
    <AssemblyVersion>1.18.0.28</AssemblyVersion>
    <AssemblyVersion>1.19.0.28</AssemblyVersion>
    <AssemblyVersion>1.20.0.28</AssemblyVersion>
    <AssemblyVersion>1.21.0.28</AssemblyVersion>
    <AssemblyVersion>1.22.0.28</AssemblyVersion>
    <AssemblyVersion>1.23.0.28</AssemblyVersion>
    <AssemblyVersion>1.24.0.28</AssemblyVersion>
    <AssemblyVersion>1.24.1.28</AssemblyVersion>
    <AssemblyVersion>1.25.1.26</AssemblyVersion>
    <AssemblyVersion>1.27.0.28</AssemblyVersion>
    <AssemblyVersion>1.28.0.28</AssemblyVersion>
    <AssemblyVersion>1.30.0.28</AssemblyVersion>
    <AssemblyVersion>1.31.0.28</AssemblyVersion>
    <AssemblyVersion>1.32.1.28</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>
            Lists speech property IDs.
            </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="AudioConfig_DeviceNameForRender">
      <MemberSignature Language="C#" Value="AudioConfig_DeviceNameForRender" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId AudioConfig_DeviceNameForRender = int32(8005)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.AudioConfig_DeviceNameForRender" />
      <MemberSignature Language="VB.NET" Value="AudioConfig_DeviceNameForRender" />
      <MemberSignature Language="F#" Value="AudioConfig_DeviceNameForRender = 8005" Usage="Microsoft.CognitiveServices.Speech.PropertyId.AudioConfig_DeviceNameForRender" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>8005</MemberValue>
      <Docs>
        <summary>
            The device name for audio render. Under normal circumstances, you shouldn't have to
            use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromSpeakerOutput(System.String)" />.
            Added in version 1.17.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="AudioConfig_PlaybackBufferLengthInMs">
      <MemberSignature Language="C#" Value="AudioConfig_PlaybackBufferLengthInMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId AudioConfig_PlaybackBufferLengthInMs = int32(8006)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs" />
      <MemberSignature Language="VB.NET" Value="AudioConfig_PlaybackBufferLengthInMs" />
      <MemberSignature Language="F#" Value="AudioConfig_PlaybackBufferLengthInMs = 8006" Usage="Microsoft.CognitiveServices.Speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>8006</MemberValue>
      <Docs>
        <summary>
            Playback buffer length in milliseconds, default is 50 milliseconds.
            Added in version 1.17.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="CancellationDetails_Reason">
      <MemberSignature Language="C#" Value="CancellationDetails_Reason" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId CancellationDetails_Reason = int32(6000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_Reason" />
      <MemberSignature Language="VB.NET" Value="CancellationDetails_Reason" />
      <MemberSignature Language="F#" Value="CancellationDetails_Reason = 6000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_Reason" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>6000</MemberValue>
      <Docs>
        <summary>
            Unused. The cancellation reason.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="CancellationDetails_ReasonDetailedText">
      <MemberSignature Language="C#" Value="CancellationDetails_ReasonDetailedText" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId CancellationDetails_ReasonDetailedText = int32(6002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_ReasonDetailedText" />
      <MemberSignature Language="VB.NET" Value="CancellationDetails_ReasonDetailedText" />
      <MemberSignature Language="F#" Value="CancellationDetails_ReasonDetailedText = 6002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_ReasonDetailedText" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>6002</MemberValue>
      <Docs>
        <summary>
            Unused. The cancellation detailed text.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="CancellationDetails_ReasonText">
      <MemberSignature Language="C#" Value="CancellationDetails_ReasonText" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId CancellationDetails_ReasonText = int32(6001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_ReasonText" />
      <MemberSignature Language="VB.NET" Value="CancellationDetails_ReasonText" />
      <MemberSignature Language="F#" Value="CancellationDetails_ReasonText = 6001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_ReasonText" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>6001</MemberValue>
      <Docs>
        <summary>
            Unused. The cancellation text.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_ApplicationId">
      <MemberSignature Language="C#" Value="Conversation_ApplicationId" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_ApplicationId = int32(10000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_ApplicationId" />
      <MemberSignature Language="VB.NET" Value="Conversation_ApplicationId" />
      <MemberSignature Language="F#" Value="Conversation_ApplicationId = 10000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_ApplicationId" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10000</MemberValue>
      <Docs>
        <summary>
            Identifier used to connect to the backend service.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_Connection_Id">
      <MemberSignature Language="C#" Value="Conversation_Connection_Id" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_Connection_Id = int32(10009)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Connection_Id" />
      <MemberSignature Language="VB.NET" Value="Conversation_Connection_Id" />
      <MemberSignature Language="F#" Value="Conversation_Connection_Id = 10009" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Connection_Id" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10009</MemberValue>
      <Docs>
        <summary>
            Additional identifying information, such as a Direct Line token, used to authenticate with the backend service.
            Added in 1.16.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_Conversation_Id">
      <MemberSignature Language="C#" Value="Conversation_Conversation_Id" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_Conversation_Id = int32(10004)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Conversation_Id" />
      <MemberSignature Language="VB.NET" Value="Conversation_Conversation_Id" />
      <MemberSignature Language="F#" Value="Conversation_Conversation_Id = 10004" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Conversation_Id" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10004</MemberValue>
      <Docs>
        <summary>
            ConversationId for the session.
            Added in 1.8.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_Custom_Voice_Deployment_Ids">
      <MemberSignature Language="C#" Value="Conversation_Custom_Voice_Deployment_Ids" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_Custom_Voice_Deployment_Ids = int32(10005)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids" />
      <MemberSignature Language="VB.NET" Value="Conversation_Custom_Voice_Deployment_Ids" />
      <MemberSignature Language="F#" Value="Conversation_Custom_Voice_Deployment_Ids = 10005" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10005</MemberValue>
      <Docs>
        <summary>
            Comma separated list of custom voice deployment ids.
            Added in 1.8.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_DialogType">
      <MemberSignature Language="C#" Value="Conversation_DialogType" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_DialogType = int32(10001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_DialogType" />
      <MemberSignature Language="VB.NET" Value="Conversation_DialogType" />
      <MemberSignature Language="F#" Value="Conversation_DialogType = 10001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_DialogType" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10001</MemberValue>
      <Docs>
        <summary>
            Type of dialog backend to connect to.
            Added in 1.7.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_From_Id">
      <MemberSignature Language="C#" Value="Conversation_From_Id" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_From_Id = int32(10003)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_From_Id" />
      <MemberSignature Language="VB.NET" Value="Conversation_From_Id" />
      <MemberSignature Language="F#" Value="Conversation_From_Id = 10003" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_From_Id" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10003</MemberValue>
      <Docs>
        <summary>
            The from identifier to add to speech recognition activities.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_Initial_Silence_Timeout">
      <MemberSignature Language="C#" Value="Conversation_Initial_Silence_Timeout" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_Initial_Silence_Timeout = int32(10002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Initial_Silence_Timeout" />
      <MemberSignature Language="VB.NET" Value="Conversation_Initial_Silence_Timeout" />
      <MemberSignature Language="F#" Value="Conversation_Initial_Silence_Timeout = 10002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Initial_Silence_Timeout" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10002</MemberValue>
      <Docs>
        <summary>
            Silence timeout for listening.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_ParticipantId">
      <MemberSignature Language="C#" Value="Conversation_ParticipantId" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_ParticipantId = int32(10007)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_ParticipantId" />
      <MemberSignature Language="VB.NET" Value="Conversation_ParticipantId" />
      <MemberSignature Language="F#" Value="Conversation_ParticipantId = 10007" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_ParticipantId" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10007</MemberValue>
      <Docs>
        <summary>
            Gets your identifier in the conversation.
            Added in 1.13.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_Request_Bot_Status_Messages">
      <MemberSignature Language="C#" Value="Conversation_Request_Bot_Status_Messages" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_Request_Bot_Status_Messages = int32(10008)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Request_Bot_Status_Messages" />
      <MemberSignature Language="VB.NET" Value="Conversation_Request_Bot_Status_Messages" />
      <MemberSignature Language="F#" Value="Conversation_Request_Bot_Status_Messages = 10008" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Request_Bot_Status_Messages" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10008</MemberValue>
      <Docs>
        <summary>
            A boolean value that specifies whether or not the client should receive turn status messages and generate
            corresponding TurnStatusReceived events. Defaults to true.
            Added in 1.15.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Conversation_Speech_Activity_Template">
      <MemberSignature Language="C#" Value="Conversation_Speech_Activity_Template" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Conversation_Speech_Activity_Template = int32(10006)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Speech_Activity_Template" />
      <MemberSignature Language="VB.NET" Value="Conversation_Speech_Activity_Template" />
      <MemberSignature Language="F#" Value="Conversation_Speech_Activity_Template = 10006" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Speech_Activity_Template" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>10006</MemberValue>
      <Docs>
        <summary>
            Speech activity template, stamp properties from the template on the activity generated by the service for speech. See <see cref="P:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.SpeechActivityTemplate" />
            Added in 1.10.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="ConversationTranscribingService_DataBufferTimeStamp">
      <MemberSignature Language="C#" Value="ConversationTranscribingService_DataBufferTimeStamp" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId ConversationTranscribingService_DataBufferTimeStamp = int32(11001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.ConversationTranscribingService_DataBufferTimeStamp" />
      <MemberSignature Language="VB.NET" Value="ConversationTranscribingService_DataBufferTimeStamp" />
      <MemberSignature Language="F#" Value="ConversationTranscribingService_DataBufferTimeStamp = 11001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.ConversationTranscribingService_DataBufferTimeStamp" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>11001</MemberValue>
      <Docs>
        <summary>
            The time stamp associated to data buffer written by client when using Pull/Push audio mode streams.
            The time stamp is a 64-bit value with a resolution of 90 kHz. The same as the presentation timestamp in an MPEG transport stream.
            See https://en.wikipedia.org/wiki/Presentation_timestamp.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="ConversationTranscribingService_DataBufferUserId">
      <MemberSignature Language="C#" Value="ConversationTranscribingService_DataBufferUserId" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId ConversationTranscribingService_DataBufferUserId = int32(11002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.ConversationTranscribingService_DataBufferUserId" />
      <MemberSignature Language="VB.NET" Value="ConversationTranscribingService_DataBufferUserId" />
      <MemberSignature Language="F#" Value="ConversationTranscribingService_DataBufferUserId = 11002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.ConversationTranscribingService_DataBufferUserId" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>11002</MemberValue>
      <Docs>
        <summary>
            The user identifier associated to data buffer written by client when using Pull/Push audio mode streams.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="LanguageUnderstandingServiceResponse_JsonResult">
      <MemberSignature Language="C#" Value="LanguageUnderstandingServiceResponse_JsonResult" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId LanguageUnderstandingServiceResponse_JsonResult = int32(7000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult" />
      <MemberSignature Language="VB.NET" Value="LanguageUnderstandingServiceResponse_JsonResult" />
      <MemberSignature Language="F#" Value="LanguageUnderstandingServiceResponse_JsonResult = 7000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>7000</MemberValue>
      <Docs>
        <summary>
            The Language Understanding Service response output (in JSON format). Available via <see cref="P:Microsoft.CognitiveServices.Speech.RecognitionResult.Properties" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_EnableMiscue">
      <MemberSignature Language="C#" Value="PronunciationAssessment_EnableMiscue" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_EnableMiscue = int32(12005)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_EnableMiscue" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_EnableMiscue" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_EnableMiscue = 12005" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_EnableMiscue" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12005</MemberValue>
      <Docs>
        <summary>
            Indicates miscue calculation state.
            When enabled, the pronounced words will be compared to the reference text,
            and will be marked with omission/insertion based on the comparison. The default setting is false.
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in 1.14.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_GradingSystem">
      <MemberSignature Language="C#" Value="PronunciationAssessment_GradingSystem" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_GradingSystem = int32(12002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_GradingSystem" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_GradingSystem" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_GradingSystem = 12002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_GradingSystem" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12002</MemberValue>
      <Docs>
        <summary>
            The point system for pronunciation score calibration (FivePoint or HundredMark).
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in 1.14.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_Granularity">
      <MemberSignature Language="C#" Value="PronunciationAssessment_Granularity" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_Granularity = int32(12003)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Granularity" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_Granularity" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_Granularity = 12003" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Granularity" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12003</MemberValue>
      <Docs>
        <summary>
            The pronunciation evaluation granularity (Phoneme, Word, or FullText).
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in 1.14.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_Json">
      <MemberSignature Language="C#" Value="PronunciationAssessment_Json" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_Json = int32(12009)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Json" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_Json" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_Json = 12009" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Json" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12009</MemberValue>
      <Docs>
        <summary>
            The JSON string of pronunciation assessment parameters.
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in 1.14.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_NBestPhonemeCount">
      <MemberSignature Language="C#" Value="PronunciationAssessment_NBestPhonemeCount" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_NBestPhonemeCount = int32(12007)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_NBestPhonemeCount" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_NBestPhonemeCount" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_NBestPhonemeCount = 12007" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_NBestPhonemeCount" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12007</MemberValue>
      <Docs>
        <summary>
            The pronunciation evaluation nbest phoneme count.
            Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.NBestPhonemeCount" />.
            Added in version 1.20.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_Params">
      <MemberSignature Language="C#" Value="PronunciationAssessment_Params" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_Params = int32(12010)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Params" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_Params" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_Params = 12010" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Params" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12010</MemberValue>
      <Docs>
        <summary>
            Pronunciation assessment parameters.
            This property is read-only.
            Added in 1.14.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_PhonemeAlphabet">
      <MemberSignature Language="C#" Value="PronunciationAssessment_PhonemeAlphabet" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_PhonemeAlphabet = int32(12006)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_PhonemeAlphabet" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_PhonemeAlphabet" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_PhonemeAlphabet = 12006" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_PhonemeAlphabet" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12006</MemberValue>
      <Docs>
        <summary>
            The pronunciation evaluation phoneme alphabet. The valid values are "SAPI" (default) and "IPA"
            Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.PhonemeAlphabet" />.
            Added in version 1.20.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="PronunciationAssessment_ReferenceText">
      <MemberSignature Language="C#" Value="PronunciationAssessment_ReferenceText" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId PronunciationAssessment_ReferenceText = int32(12001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_ReferenceText" />
      <MemberSignature Language="VB.NET" Value="PronunciationAssessment_ReferenceText" />
      <MemberSignature Language="F#" Value="PronunciationAssessment_ReferenceText = 12001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_ReferenceText" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>12001</MemberValue>
      <Docs>
        <summary>
            The reference text of the audio for pronunciation evaluation.
            For this and the following pronunciation assessment parameters, see
            [Pronunciation assessment parameters](/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters) for details.
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in 1.14.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeakerRecognition_Api_Version">
      <MemberSignature Language="C#" Value="SpeakerRecognition_Api_Version" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeakerRecognition_Api_Version = int32(13001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeakerRecognition_Api_Version" />
      <MemberSignature Language="VB.NET" Value="SpeakerRecognition_Api_Version" />
      <MemberSignature Language="F#" Value="SpeakerRecognition_Api_Version = 13001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeakerRecognition_Api_Version" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>13001</MemberValue>
      <Docs>
        <summary>
            Speaker recognition API version.
            Added in 1.18.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Speech_LogFilename">
      <MemberSignature Language="C#" Value="Speech_LogFilename" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Speech_LogFilename = int32(9001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Speech_LogFilename" />
      <MemberSignature Language="VB.NET" Value="Speech_LogFilename" />
      <MemberSignature Language="F#" Value="Speech_LogFilename = 9001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Speech_LogFilename" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>9001</MemberValue>
      <Docs>
        <summary>
            The file name to write logs.
            Added in 1.4.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="Speech_SegmentationSilenceTimeoutMs">
      <MemberSignature Language="C#" Value="Speech_SegmentationSilenceTimeoutMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Speech_SegmentationSilenceTimeoutMs = int32(9002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Speech_SegmentationSilenceTimeoutMs" />
      <MemberSignature Language="VB.NET" Value="Speech_SegmentationSilenceTimeoutMs" />
      <MemberSignature Language="F#" Value="Speech_SegmentationSilenceTimeoutMs = 9002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Speech_SegmentationSilenceTimeoutMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>9002</MemberValue>
      <Docs>
        <summary>
             A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken
             phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations
             where spoken input is significantly faster or slower than usual and default segmentation behavior consistently
             yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low
             can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting
             behavior should be thoroughly validated as intended.
            
             For more information about timeout configuration that includes discussion of default behaviors, please visit
             https://aka.ms/csspeech/timeouts.
             </summary>
      </Docs>
    </Member>
    <Member MemberName="Speech_SessionId">
      <MemberSignature Language="C#" Value="Speech_SessionId" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId Speech_SessionId = int32(3002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.Speech_SessionId" />
      <MemberSignature Language="VB.NET" Value="Speech_SessionId" />
      <MemberSignature Language="F#" Value="Speech_SessionId = 3002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.Speech_SessionId" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3002</MemberValue>
      <Docs>
        <summary>
            The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream
            and the underlying speech recognition instance to which it is bound. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="P:Microsoft.CognitiveServices.Speech.SessionEventArgs.SessionId" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceAuthorization_Token">
      <MemberSignature Language="C#" Value="SpeechServiceAuthorization_Token" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceAuthorization_Token = int32(1003)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceAuthorization_Token" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceAuthorization_Token" />
      <MemberSignature Language="F#" Value="SpeechServiceAuthorization_Token = 1003" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceAuthorization_Token" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1003</MemberValue>
      <Docs>
        <summary>
            The Speech service authorization token (aka access token). Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromAuthorizationToken(System.String,System.String)" />,
            <see cref="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken" />, <see cref="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AuthorizationToken" />,
            <see cref="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.AuthorizationToken" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceAuthorization_Type">
      <MemberSignature Language="C#" Value="SpeechServiceAuthorization_Type" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceAuthorization_Type = int32(1004)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceAuthorization_Type" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceAuthorization_Type" />
      <MemberSignature Language="F#" Value="SpeechServiceAuthorization_Type = 1004" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceAuthorization_Type" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1004</MemberValue>
      <Docs>
        <summary>
            Unused. The Speech service authorization type.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_AutoDetectSourceLanguageResult">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_AutoDetectSourceLanguageResult" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_AutoDetectSourceLanguageResult = int32(3301)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_AutoDetectSourceLanguageResult" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_AutoDetectSourceLanguageResult = 3301" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3301</MemberValue>
      <Docs>
        <summary>
            The auto detect source language result.
            Added in 1.9.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_AutoDetectSourceLanguages">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_AutoDetectSourceLanguages" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_AutoDetectSourceLanguages = int32(3300)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_AutoDetectSourceLanguages" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_AutoDetectSourceLanguages = 3300" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3300</MemberValue>
      <Docs>
        <summary>
            The auto detect source languages.
            Added in 1.9.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_EnableAudioLogging">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_EnableAudioLogging" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_EnableAudioLogging = int32(3202)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EnableAudioLogging" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_EnableAudioLogging" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_EnableAudioLogging = 3202" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EnableAudioLogging" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3202</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether audio logging is enabled in the service or not.
            Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked
            to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).
            Added in 1.5.0.
            </summary>
        <remarks>
            Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked
            to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).
            </remarks>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_Endpoint">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_Endpoint" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_Endpoint = int32(1001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Endpoint" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_Endpoint" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_Endpoint = 1001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Endpoint" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1001</MemberValue>
      <Docs>
        <summary>
            The Speech service endpoint, a URL. Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead, use  <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)" />, or <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)" />.
            NOTE: This endpoint is not the same as the endpoint used to obtain an access token.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_EndpointId">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_EndpointId" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_EndpointId = int32(1005)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EndpointId" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_EndpointId" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_EndpointId = 1005" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EndpointId" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1005</MemberValue>
      <Docs>
        <summary>
            The Custom Speech or Custom Voice Service endpoint id. Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)" />, or <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)" />.
            NOTE: The endpoint id is available in the Custom Speech Portal, listed under Endpoint Details.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_EndSilenceTimeoutMs">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_EndSilenceTimeoutMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_EndSilenceTimeoutMs = int32(3201)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_EndSilenceTimeoutMs" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_EndSilenceTimeoutMs = 3201" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3201</MemberValue>
      <Docs>
        <summary>
            The end silence timeout value (in milliseconds) used by the service.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_Host">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_Host" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_Host = int32(1006)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Host" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_Host" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_Host = 1006" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Host" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1006</MemberValue>
      <Docs>
        <summary>
            The Speech service host (url). Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri,System.String)" />, or <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri)" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_InitialSilenceTimeoutMs">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_InitialSilenceTimeoutMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_InitialSilenceTimeoutMs = int32(3200)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_InitialSilenceTimeoutMs" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_InitialSilenceTimeoutMs = 3200" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3200</MemberValue>
      <Docs>
        <summary>
            The initial silence timeout value (in milliseconds) used by the service.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_IntentRegion">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_IntentRegion" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_IntentRegion = int32(2003)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_IntentRegion" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_IntentRegion" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_IntentRegion = 2003" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_IntentRegion" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>2003</MemberValue>
      <Docs>
        <summary>
            The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.
            Instead use <see cref="T:Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_Key">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_Key" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_Key = int32(1000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Key" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_Key" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_Key = 1000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Key" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1000</MemberValue>
      <Docs>
        <summary>
            The subscription key used with Speech service endpoints. If you are using an intent recognizer, you need
            to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromSubscription(System.String,System.String)" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_LanguageIdMode">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_LanguageIdMode" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_LanguageIdMode = int32(3205)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_LanguageIdMode" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_LanguageIdMode" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_LanguageIdMode = 3205" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_LanguageIdMode" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3205</MemberValue>
      <Docs>
        <summary>
            The speech service connection language identifier mode.
            Can be "AtStart" (the default), or "Continuous". See [Language
            Identification](https://aka.ms/speech/lid?pivots=programming-language-csharp) document.
            Added in 1.25.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_ProxyHostName">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_ProxyHostName" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_ProxyHostName = int32(1100)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyHostName" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_ProxyHostName" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_ProxyHostName = 1100" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyHostName" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1100</MemberValue>
      <Docs>
        <summary>
            The host name of the proxy server used to connect to the Speech service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)" />.
            Added in 1.1.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_ProxyPassword">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_ProxyPassword" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_ProxyPassword = int32(1103)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyPassword" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_ProxyPassword" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_ProxyPassword = 1103" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyPassword" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1103</MemberValue>
      <Docs>
        <summary>
            The password of the proxy server used to connect to the Speech service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)" />.
            Added in 1.1.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_ProxyPort">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_ProxyPort" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_ProxyPort = int32(1101)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyPort" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_ProxyPort" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_ProxyPort = 1101" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyPort" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1101</MemberValue>
      <Docs>
        <summary>
            The port of the proxy server used to connect to the Speech service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)" />.
            Added in 1.1.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_ProxyUserName">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_ProxyUserName" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_ProxyUserName = int32(1102)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyUserName" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_ProxyUserName" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_ProxyUserName = 1102" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyUserName" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1102</MemberValue>
      <Docs>
        <summary>
            The user name of the proxy server used to connect to the Speech service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)" />.
            Added in 1.1.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_RecoBackend">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_RecoBackend" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_RecoBackend = int32(3004)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoBackend" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_RecoBackend" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_RecoBackend = 3004" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoBackend" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3004</MemberValue>
      <Docs>
        <summary>
            The string to specify the backend to be used for speech recognition;
            allowed options are online and offline.
            Under normal circumstances, you shouldn't use this property directly.
            Currently the offline option is only valid when EmbeddedSpeechConfig is used.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_RecoLanguage">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_RecoLanguage" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_RecoLanguage = int32(3001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoLanguage" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_RecoLanguage" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_RecoLanguage = 3001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoLanguage" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3001</MemberValue>
      <Docs>
        <summary>
            The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechRecognitionLanguage" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_RecoMode">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_RecoMode" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_RecoMode = int32(3000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoMode" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_RecoMode" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_RecoMode = 3000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoMode" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3000</MemberValue>
      <Docs>
        <summary>
            The Speech service recognition mode. Can be INTERACTIVE, CONVERSATION, DICTATION.
            This property is read-only. The SDK uses it internally.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_RecoModelKey">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_RecoModelKey" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_RecoModelKey = int32(3006)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoModelKey" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_RecoModelKey" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_RecoModelKey = 3006" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoModelKey" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3006</MemberValue>
      <Docs>
        <summary>
            The decryption key of the model to be used for speech recognition.
            Under normal circumstances, you shouldn't use this property directly.
            Currently this is only valid when EmbeddedSpeechConfig is used.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_RecoModelName">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_RecoModelName" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_RecoModelName = int32(3005)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoModelName" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_RecoModelName" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_RecoModelName = 3005" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoModelName" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3005</MemberValue>
      <Docs>
        <summary>
            The name of the model to be used for speech recognition.
            Under normal circumstances, you shouldn't use this property directly.
            Currently this is only valid when EmbeddedSpeechConfig is used.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_Region">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_Region" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_Region = int32(1002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Region" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_Region" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_Region = 1002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Region" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1002</MemberValue>
      <Docs>
        <summary>
            The Speech service region associated with the subscription key. Under normal circumstances, you shouldn't have to
            use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromSubscription(System.String,System.String)" />, <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)" />,
            <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)" />, <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri,System.String)" />,
            <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri)" />, <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromAuthorizationToken(System.String,System.String)" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthBackend">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthBackend" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthBackend = int32(3110)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthBackend" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthBackend" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthBackend = 3110" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthBackend" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3110</MemberValue>
      <Docs>
        <summary>
            The string to specify TTS backend; valid options are online and offline.
            Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig.FromPath(System.String)" /> or <see cref="M:Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig.FromPaths(System.String[])" />.
            to set the synthesis backend to offline.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthEnableCompressedAudioTransmission">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthEnableCompressedAudioTransmission" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthEnableCompressedAudioTransmission = int32(3103)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthEnableCompressedAudioTransmission" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthEnableCompressedAudioTransmission = 3103" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3103</MemberValue>
      <Docs>
        <summary>
            Indicates whether to use compressed audio format for speech synthesis audio transmission.
            This property only matters when SpeechServiceConnection_SynthOutputFormat is set to a pcm format.
            If this property is not set to true and GStreamer is available, SDK will use compressed format for synthesized audio transmission,
            and decode it. You can set this property to false to use raw pcm format for transmission on wire.
            Added in 1.16.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthLanguage">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthLanguage" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthLanguage = int32(3100)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthLanguage" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthLanguage" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthLanguage = 3100" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthLanguage" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3100</MemberValue>
      <Docs>
        <summary>
            The spoken language to be synthesized (e.g. en-US).
            Added in 1.4.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthModelKey">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthModelKey" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthModelKey = int32(3114)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthModelKey" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthModelKey" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthModelKey = 3114" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthModelKey" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3114</MemberValue>
      <Docs>
        <summary>
            The decryption key of the model to be used for speech synthesis.
            Under normal circumstances, you shouldn't use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig.SetSpeechSynthesisVoice(System.String,System.String)" />.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthOfflineDataPath">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthOfflineDataPath" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthOfflineDataPath = int32(3112)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthOfflineDataPath" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthOfflineDataPath = 3112" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3112</MemberValue>
      <Docs>
        <summary>
            The data file path(s) for offline synthesis engine; only valid when synthesis backend is offline.
            Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig.FromPath(System.String)" /> or <see cref="M:Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig.FromPaths(System.String[])" />.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthOfflineVoice">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthOfflineVoice" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthOfflineVoice = int32(3113)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthOfflineVoice" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthOfflineVoice = 3113" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3113</MemberValue>
      <Docs>
        <summary>
            The name of the offline TTS voice to be used for speech synthesis.
            Under normal circumstances, you shouldn't use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig.SetSpeechSynthesisVoice(System.String,System.String)" />.
            Added in version 1.19.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthOutputFormat">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthOutputFormat" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthOutputFormat = int32(3102)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOutputFormat" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthOutputFormat" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthOutputFormat = 3102" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOutputFormat" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3102</MemberValue>
      <Docs>
        <summary>
            The string to specify speech synthesis output audio format (e.g. riff-16khz-16bit-mono-pcm)
            Added in 1.4.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_SynthVoice">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_SynthVoice" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_SynthVoice = int32(3101)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthVoice" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_SynthVoice" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_SynthVoice = 3101" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthVoice" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3101</MemberValue>
      <Docs>
        <summary>
            The name of the voice to be used for Text-to-speech.
            Added in 1.4.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_TranslationFeatures">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_TranslationFeatures" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_TranslationFeatures = int32(2002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationFeatures" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_TranslationFeatures" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_TranslationFeatures = 2002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationFeatures" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>2002</MemberValue>
      <Docs>
        <summary>
            Translation features. For internal use.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_TranslationToLanguages">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_TranslationToLanguages" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_TranslationToLanguages = int32(2000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationToLanguages" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_TranslationToLanguages" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_TranslationToLanguages = 2000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationToLanguages" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>2000</MemberValue>
      <Docs>
        <summary>
            The list of comma separated languages (in BCP-47 format) used as target translation languages. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.AddTargetLanguage(System.String)" /> and the read-only <see cref="P:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.TargetLanguages" /> collection.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_TranslationVoice">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_TranslationVoice" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_TranslationVoice = int32(2001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationVoice" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_TranslationVoice" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_TranslationVoice = 2001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationVoice" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>2001</MemberValue>
      <Docs>
        <summary>
            The name of the voice used for Text-to-speech. Under normal circumstances, you shouldn't have to use this
            property directly. Instead use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.VoiceName" />.
            Find valid voice names <a href="/azure/cognitive-services/speech-service/language-support#text-to-speech">here</a>.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_Url">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_Url" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_Url = int32(1104)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Url" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_Url" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_Url = 1104" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Url" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>1104</MemberValue>
      <Docs>
        <summary>
            The URL string built from speech configuration.
            This property is read-only. The SDK uses this value internally.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceConnection_VoicesListEndpoint">
      <MemberSignature Language="C#" Value="SpeechServiceConnection_VoicesListEndpoint" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceConnection_VoicesListEndpoint = int32(3130)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceConnection_VoicesListEndpoint" />
      <MemberSignature Language="F#" Value="SpeechServiceConnection_VoicesListEndpoint = 3130" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>3130</MemberValue>
      <Docs>
        <summary>
            The Cognitive Services Speech Service voices list API endpoint (url). Under normal circumstances,
            you don't need to specify this property, SDK will construct it based on the region/host/endpoint of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechConfig" />.
            Added in 1.16.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_JsonErrorDetails">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_JsonErrorDetails" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_JsonErrorDetails = int32(5001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_JsonErrorDetails" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_JsonErrorDetails" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_JsonErrorDetails = 5001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_JsonErrorDetails" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5001</MemberValue>
      <Docs>
        <summary>
            The Speech service error details (in JSON format). Under normal circumstances, you shouldn't have to
            use this property directly. Instead use <see cref="P:Microsoft.CognitiveServices.Speech.CancellationDetails.ErrorDetails" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_JsonResult">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_JsonResult" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_JsonResult = int32(5000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_JsonResult" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_JsonResult" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_JsonResult = 5000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_JsonResult" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5000</MemberValue>
      <Docs>
        <summary>
            The Speech service response output (in JSON format). This property is available on
            recognition result objects only.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_OutputFormatOption">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_OutputFormatOption" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_OutputFormatOption = int32(4006)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_OutputFormatOption" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_OutputFormatOption" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_OutputFormatOption = 4006" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_OutputFormatOption" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4006</MemberValue>
      <Docs>
        <summary>
            A string value specifying the output format option in the response result. Internal use only.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_PostProcessingOption">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_PostProcessingOption" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_PostProcessingOption = int32(4003)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_PostProcessingOption" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_PostProcessingOption" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_PostProcessingOption = 4003" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_PostProcessingOption" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4003</MemberValue>
      <Docs>
        <summary>
            A string value specifying which post processing option should be used by service.
            Allowed value: TrueText.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_ProfanityOption">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_ProfanityOption" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_ProfanityOption = int32(4002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_ProfanityOption" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_ProfanityOption" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_ProfanityOption = 4002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_ProfanityOption" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4002</MemberValue>
      <Docs>
        <summary>
            The requested Speech service response output profanity setting.
            Allowed values are masked, removed, and raw.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RecognitionBackend">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RecognitionBackend" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RecognitionBackend = int32(5003)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RecognitionBackend" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RecognitionBackend" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RecognitionBackend = 5003" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RecognitionBackend" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5003</MemberValue>
      <Docs>
        <summary>
            The recognition backend. Read-only, available on speech recognition results.
            This indicates whether cloud (online) or embedded (offline) recognition was used to produce the result.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RecognitionLatencyMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RecognitionLatencyMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RecognitionLatencyMs = int32(5002)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RecognitionLatencyMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RecognitionLatencyMs = 5002" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5002</MemberValue>
      <Docs>
        <summary>
            The recognition latency in milliseconds. Read-only, available on final speech/translation/intent results.
            This measures the latency between when an audio input is received by the SDK, and the moment the final result is received from the service.
            The SDK computes the time difference between the last audio fragment from the audio input that is contributing to the final result, and the time the final result is received from the speech service.
            Added in 1.3.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestDetailedResultTrueFalse">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestDetailedResultTrueFalse" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestDetailedResultTrueFalse = int32(4000)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestDetailedResultTrueFalse" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestDetailedResultTrueFalse = 4000" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4000</MemberValue>
      <Docs>
        <summary>
            The requested Speech service response output format (**OutputFormat.Simple** or **OutputFormat.Detailed**).
            Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechConfig.OutputFormat" />.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestProfanityFilterTrueFalse">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestProfanityFilterTrueFalse" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestProfanityFilterTrueFalse = int32(4001)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestProfanityFilterTrueFalse" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestProfanityFilterTrueFalse = 4001" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4001</MemberValue>
      <Docs>
        <summary>
            Unused. The requested Speech service response output profanity level.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestPunctuationBoundary">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestPunctuationBoundary" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestPunctuationBoundary = int32(4201)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestPunctuationBoundary" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestPunctuationBoundary = 4201" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4201</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.
            Added in version 1.21.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestSentenceBoundary">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestSentenceBoundary" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestSentenceBoundary = int32(4202)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestSentenceBoundary" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestSentenceBoundary" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestSentenceBoundary = 4202" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestSentenceBoundary" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4202</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.
            Added in version 1.21.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestSnr">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestSnr" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestSnr = int32(4007)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestSnr" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestSnr" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestSnr = 4007" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestSnr" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4007</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether to include SNR (signal to noise ratio) in the response result.
            Added in version 1.18.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestWordBoundary">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestWordBoundary" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestWordBoundary = int32(4200)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestWordBoundary" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestWordBoundary" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestWordBoundary = 4200" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestWordBoundary" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4200</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether to request WordBoundary events.
            Added in version 1.21.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_RequestWordLevelTimestamps">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_RequestWordLevelTimestamps" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_RequestWordLevelTimestamps = int32(4004)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_RequestWordLevelTimestamps" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_RequestWordLevelTimestamps = 4004" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4004</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether to include word-level timestamps in the response result.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_StablePartialResultThreshold">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_StablePartialResultThreshold" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_StablePartialResultThreshold = int32(4005)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_StablePartialResultThreshold" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_StablePartialResultThreshold = 4005" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4005</MemberValue>
      <Docs>
        <summary>
            The number of times a word has to be in partial results to be returned.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisBackend">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisBackend" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisBackend = int32(5020)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisBackend" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisBackend" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisBackend = 5020" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisBackend" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5020</MemberValue>
      <Docs>
        <summary>
            Indicates which backend the synthesis is finished by.
            Read-only, available on speech synthesis results, except for the result in SynthesisStarted event.
            Added in version 1.19.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisConnectionLatencyMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisConnectionLatencyMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisConnectionLatencyMs = int32(5013)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisConnectionLatencyMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisConnectionLatencyMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisConnectionLatencyMs = 5013" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisConnectionLatencyMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5013</MemberValue>
      <Docs>
        <summary>
            The speech synthesis connection latency in milliseconds. Read-only, available on final speech synthesis results.
            This measures the latency between when the synthesis is started to be processed, and the moment the HTTP/WebSocket connection is established.
            Added in version 1.26.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisEventsSyncToAudio">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisEventsSyncToAudio" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisEventsSyncToAudio = int32(4210)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisEventsSyncToAudio" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisEventsSyncToAudio" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisEventsSyncToAudio = 4210" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisEventsSyncToAudio" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4210</MemberValue>
      <Docs>
        <summary>
            A boolean value specifying whether the SDK should synchronize synthesis metadata events,
            (e.g. word boundary, viseme, etc.) to the audio playback. This only takes effect when the audio is played through the SDK.
            Default is true.
            If set to false, the SDK will fire the events as they come from the service, which may be out of sync with the audio playback.
            Added in version 1.31.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisFinishLatencyMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisFinishLatencyMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisFinishLatencyMs = int32(5011)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisFinishLatencyMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisFinishLatencyMs = 5011" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5011</MemberValue>
      <Docs>
        <summary>
            The speech synthesis all bytes latency in milliseconds. Read-only, available on final speech synthesis results.
            This measures the latency between when the synthesis is started to be processed, and the moment the whole audio is synthesized.
            Added in version 1.17.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisFirstByteLatencyMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisFirstByteLatencyMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisFirstByteLatencyMs = int32(5010)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisFirstByteLatencyMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisFirstByteLatencyMs = 5010" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5010</MemberValue>
      <Docs>
        <summary>
            The speech synthesis first byte latency in milliseconds. Read-only, available on final speech synthesis results.
            This measures the latency between when the synthesis is started to be processed, and the moment the first byte audio is available.
            Added in version 1.17.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisNetworkLatencyMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisNetworkLatencyMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisNetworkLatencyMs = int32(5014)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisNetworkLatencyMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisNetworkLatencyMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisNetworkLatencyMs = 5014" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisNetworkLatencyMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5014</MemberValue>
      <Docs>
        <summary>
            The speech synthesis network latency in milliseconds. Read-only, available on final speech synthesis results.
            This measures the network round trip time.
            Added in version 1.26.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisServiceLatencyMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisServiceLatencyMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisServiceLatencyMs = int32(5015)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisServiceLatencyMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisServiceLatencyMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisServiceLatencyMs = 5015" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisServiceLatencyMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5015</MemberValue>
      <Docs>
        <summary>
            The speech synthesis service latency in milliseconds. Read-only, available on final speech synthesis results.
            This measures the service processing time to synthesize the first byte of audio.
            Added in version 1.26.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_SynthesisUnderrunTimeMs">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_SynthesisUnderrunTimeMs" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_SynthesisUnderrunTimeMs = int32(5012)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_SynthesisUnderrunTimeMs" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_SynthesisUnderrunTimeMs = 5012" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>5012</MemberValue>
      <Docs>
        <summary>
            The underrun time for speech synthesis in milliseconds. Read-only, available on results in SynthesisCompleted events.
            This measures the total underrun time from <see cref="F:Microsoft.CognitiveServices.Speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs" /> is filled to synthesis completed.
            Added in version 1.17.0.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechServiceResponse_TranslationRequestStablePartialResult">
      <MemberSignature Language="C#" Value="SpeechServiceResponse_TranslationRequestStablePartialResult" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechServiceResponse_TranslationRequestStablePartialResult = int32(4100)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult" />
      <MemberSignature Language="VB.NET" Value="SpeechServiceResponse_TranslationRequestStablePartialResult" />
      <MemberSignature Language="F#" Value="SpeechServiceResponse_TranslationRequestStablePartialResult = 4100" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>4100</MemberValue>
      <Docs>
        <summary>
            A boolean value to request for stabilizing translation partial results by omitting words in the end.
            Added in 1.5.0
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechTranslation_ModelKey">
      <MemberSignature Language="C#" Value="SpeechTranslation_ModelKey" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechTranslation_ModelKey = int32(13101)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechTranslation_ModelKey" />
      <MemberSignature Language="VB.NET" Value="SpeechTranslation_ModelKey" />
      <MemberSignature Language="F#" Value="SpeechTranslation_ModelKey = 13101" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechTranslation_ModelKey" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>13101</MemberValue>
      <Docs>
        <summary>
            The decryption key of a model to be used for speech translation.
            Do not use this property directly.
            Currently this is only valid when EmbeddedSpeechConfig is used.
            </summary>
      </Docs>
    </Member>
    <Member MemberName="SpeechTranslation_ModelName">
      <MemberSignature Language="C#" Value="SpeechTranslation_ModelName" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype Microsoft.CognitiveServices.Speech.PropertyId SpeechTranslation_ModelName = int32(13100)" />
      <MemberSignature Language="DocId" Value="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechTranslation_ModelName" />
      <MemberSignature Language="VB.NET" Value="SpeechTranslation_ModelName" />
      <MemberSignature Language="F#" Value="SpeechTranslation_ModelName = 13100" Usage="Microsoft.CognitiveServices.Speech.PropertyId.SpeechTranslation_ModelName" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyId</ReturnType>
      </ReturnValue>
      <MemberValue>13100</MemberValue>
      <Docs>
        <summary>
            The name of a model to be used for speech translation.
            Do not use this property directly.
            Currently this is only valid when EmbeddedSpeechConfig is used.
            </summary>
      </Docs>
    </Member>
  </Members>
</Type>
