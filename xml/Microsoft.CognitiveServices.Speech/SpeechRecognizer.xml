<Type Name="SpeechRecognizer" FullName="Microsoft.CognitiveServices.Speech.SpeechRecognizer">
  <TypeSignature Language="C#" Value="public sealed class SpeechRecognizer : Microsoft.CognitiveServices.Speech.Recognizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit SpeechRecognizer extends Microsoft.CognitiveServices.Speech.Recognizer" />
  <TypeSignature Language="DocId" Value="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class SpeechRecognizer&#xA;Inherits Recognizer" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    inherit Recognizer" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
    <AssemblyVersion>1.16.0.28</AssemblyVersion>
    <AssemblyVersion>1.17.0.28</AssemblyVersion>
    <AssemblyVersion>1.18.0.28</AssemblyVersion>
    <AssemblyVersion>1.19.0.28</AssemblyVersion>
    <AssemblyVersion>1.20.0.28</AssemblyVersion>
    <AssemblyVersion>1.21.0.28</AssemblyVersion>
    <AssemblyVersion>1.22.0.28</AssemblyVersion>
    <AssemblyVersion>1.23.0.28</AssemblyVersion>
    <AssemblyVersion>1.24.0.28</AssemblyVersion>
    <AssemblyVersion>1.24.1.28</AssemblyVersion>
    <AssemblyVersion>1.25.1.26</AssemblyVersion>
    <AssemblyVersion>1.27.0.28</AssemblyVersion>
    <AssemblyVersion>1.28.0.28</AssemblyVersion>
    <AssemblyVersion>1.30.0.28</AssemblyVersion>
    <AssemblyVersion>1.31.0.28</AssemblyVersion>
    <AssemblyVersion>1.32.1.28</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.CognitiveServices.Speech.Recognizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
             Transcribes speech into text. Speech can arrive via microphone, audio file, or other audio input stream.
             </summary>
    <remarks>
             See also: [Get started with speech-to-text](/azure/cognitive-services/speech-service/get-started-speech-to-text)
             </remarks>
    <example>
             This example uses the speech recognizer from a microphone and listens to events generated by the recognizer.
             <code language="c#">
             public async Task SpeechContinuousRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer from microphone.
                 using (var recognizer = new SpeechRecognizer(config))
                 {
                     // Subscribes to events.
                     recognizer.Recognizing += (s, e) =&gt; {
                         Console.WriteLine($"RECOGNIZING: Text={e.Result.Text}");
                     };
            
                     recognizer.Recognized += (s, e) =&gt; {
                         var result = e.Result;
                         Console.WriteLine($"Reason: {result.Reason.ToString()}");
                         if (result.Reason == ResultReason.RecognizedSpeech)
                         {
                                 Console.WriteLine($"Final result: Text: {result.Text}.");
                         }
                     };
            
                     recognizer.Canceled += (s, e) =&gt; {
                         Console.WriteLine($"\n    Canceled. Reason: {e.Reason.ToString()}, CanceledReason: {e.Reason}");
                     };
            
                     recognizer.SessionStarted += (s, e) =&gt; {
                         Console.WriteLine("\n    Session started event.");
                     };
            
                     recognizer.SessionStopped += (s, e) =&gt; {
                         Console.WriteLine("\n    Session stopped event.");
                     };
            
                     // Starts continuous recognition. 
                     // Uses StopContinuousRecognitionAsync() to stop recognition.
                     await recognizer.StartContinuousRecognitionAsync().ConfigureAwait(false);
            
                     do
                     {
                         Console.WriteLine("Press Enter to stop");
                     } while (Console.ReadKey().Key != ConsoleKey.Enter);
            
                     // Stops recognition.
                     await recognizer.StopContinuousRecognitionAsync().ConfigureAwait(false);
                 }
             }
             </code></example>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As EmbeddedSpeechConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer speechConfig" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Embedded speech configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer using EmbeddedSpeechConfig, configured to receive speech from the default microphone.
            Added in 1.19.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.HybridSpeechConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As HybridSpeechConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.HybridSpeechConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer speechConfig" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.HybridSpeechConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Hybrid speech configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer using HybridSpeechConfig, configured to receive speech from the default microphone.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer speechConfig" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer configured to receive speech from the default microphone.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As EmbeddedSpeechConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Embedded speech configuration</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer using EmbeddedSpeechConfig, configured to receive speech from an audio source specified in an AudioConfig object. 
            Added in 1.19.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As EmbeddedSpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, autoDetectSourceLanguageConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Embedded speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">Configuration for auto-detecting the source language</param>
        <summary>
            Creates a new instance of SpeechRecognizer, using EmbeddedSpeechConfig, that determines the source language from a list of options.
            Added in 1.20.0
            </summary>
        <remarks>
            See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.HybridSpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As HybridSpeechConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.HybridSpeechConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.HybridSpeechConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Hybrid speech configuration</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer using HybridSpeechConfig, configured to receive speech from an audio source specified in an AudioConfig object. 
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.HybridSpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As HybridSpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.HybridSpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, autoDetectSourceLanguageConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.HybridSpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Hybrid speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">Configuration for auto-detecting the source language</param>
        <summary>
            Creates a new instance of SpeechRecognizer, using HybridSpeechConfig, that determines the source language from a list of options.
            </summary>
        <remarks>
            See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer configured to receive speech from an audio source specified in an AudioConfig object. 
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, autoDetectSourceLanguageConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">Configuration that specifies the language(s) to look for in the source speech to recognize</param>
        <summary>
            Creates a new instance of SpeechRecognizer that determines the source language from a list of options.
            Added in 1.9.0
            </summary>
        <remarks>
            See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.SourceLanguageConfig sourceLanguageConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.SourceLanguageConfig sourceLanguageConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.SourceLanguageConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, sourceLanguageConfig As SourceLanguageConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.SourceLanguageConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, sourceLanguageConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="sourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.SourceLanguageConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="sourceLanguageConfig">The source language config</param>
        <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, string language);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, string language) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, language As String)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * string -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, language)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="language" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="language">The source language</param>
        <summary>
            Creates a new instance of SpeechRecognizer configured to receive speech in a particular language.
            Added in 1.9.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As EmbeddedSpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, autoDetectSourceLanguageConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.EmbeddedSpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Embedded speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">Configuration for auto-detecting the source language</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer, using EmbeddedSpeechConfig, that determines the source language from a list of options.
            Added in 1.20.0
            </summary>
        <remarks>
            See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.HybridSpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.HybridSpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As HybridSpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.HybridSpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, autoDetectSourceLanguageConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.HybridSpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Hybrid speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">Configuration for auto-detecting the source language</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer, using HybridSpeechConfig, that determines the source language from a list of options.
            </summary>
        <remarks>
            See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, autoDetectSourceLanguageConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">An instance that specifies possible source languages in the speech.</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.SourceLanguageConfig sourceLanguageConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.SourceLanguageConfig sourceLanguageConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.SourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, sourceLanguageConfig As SourceLanguageConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.SourceLanguageConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, sourceLanguageConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="sourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.SourceLanguageConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="sourceLanguageConfig">Language of the source speech, in BCP-47 format.</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, string language, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, string language, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,System.String,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, language As String, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * string * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, language, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="language" Type="System.String" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="language">The source language</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer configured to receive speech in a particular language from an audio source specified in an AudioConfig object.
            Added in 1.9.0
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AuthorizationToken">
      <MemberSignature Language="C#" Value="public string AuthorizationToken { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string AuthorizationToken" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken" />
      <MemberSignature Language="VB.NET" Value="Public Property AuthorizationToken As String" />
      <MemberSignature Language="F#" Value="member this.AuthorizationToken : string with get, set" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets authorization token used to communicate with the service.
              
            Note: Your code needs to ensure that the authorization token is valid. Before the authorization token
            expires, your code needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will produce errors during recognition.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Canceled">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; Canceled;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; Canceled" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Canceled" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event Canceled As EventHandler(Of SpeechRecognitionCanceledEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Canceled : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; " Usage="member this.Canceled : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Canceled" /> signals that the speech recognition was canceled.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected override void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overrides Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="F#" Value="override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">Flag to request disposal.</param>
        <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing" /> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose" /> (if <paramref name="disposing" /> is true) or from the finalizer (if <paramref name="disposing" /> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
        <returns />
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="EndpointId">
      <MemberSignature Language="C#" Value="public string EndpointId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string EndpointId" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.EndpointId" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property EndpointId As String" />
      <MemberSignature Language="F#" Value="member this.EndpointId : string" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.EndpointId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the endpoint ID of a custom speech model to use for speech recognition.
            </summary>
        <value>Endpoint ID of a custom speech model</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Finalize">
      <MemberSignature Language="C#" Value="~SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Finalize() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Finalize" />
      <MemberSignature Language="VB.NET" Value="Finalize ()" />
      <MemberSignature Language="F#" Value="override this.Finalize : unit -&gt; unit" Usage="speechRecognizer.Finalize " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>To be added.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputFormat">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.OutputFormat OutputFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype Microsoft.CognitiveServices.Speech.OutputFormat OutputFormat" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.OutputFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property OutputFormat As OutputFormat" />
      <MemberSignature Language="F#" Value="member this.OutputFormat : Microsoft.CognitiveServices.Speech.OutputFormat" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.OutputFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.OutputFormat</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the output format setting.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Properties">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.PropertyCollection Properties { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Microsoft.CognitiveServices.Speech.PropertyCollection Properties" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Properties" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Properties As PropertyCollection" />
      <MemberSignature Language="F#" Value="member this.Properties : Microsoft.CognitiveServices.Speech.PropertyCollection" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.Properties" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyCollection</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer" />.
            Note: The property collection is only valid until the recognizer owning this Properties is disposed or finalized.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Recognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognized" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event Recognized As EventHandler(Of SpeechRecognitionEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Recognized : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " Usage="member this.Recognized : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognized" /> signals that a final recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RecognizeOnceAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeOnceAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeOnceAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.RecognizeOnceAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function RecognizeOnceAsync () As Task(Of SpeechRecognitionResult)" />
      <MemberSignature Language="F#" Value="member this.RecognizeOnceAsync : unit -&gt; System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;" Usage="speechRecognizer.RecognizeOnceAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
             Starts speech recognition as an asynchronous operation.
             </summary>
        <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult" /></returns>
        <remarks>
             The end of a single utterance is determined by listening for silence at the end, or until a timeout period has elapsed.
             The task returns the recognized speech in **SpeechRecognitionResult.Text**.
               
             You can call **StopContinuousRecognitionAsync** to stop recognition before a phrase has been recognized.
               
             Since this method returns only a single utterance, it is suitable only for single shot recognition like command or query. 
             For long-running multi-utterance recognition, use **StartContinuousRecognitionAsync** instead.
            
             See also: [Get started with speech-to-text](/azure/cognitive-services/speech-service/get-started-speech-to-text)
             </remarks>
        <example>
             The following example creates a speech recognizer, and then gets and prints the recognition result.
             <code language="c#">
             public async Task SpeechSingleShotRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
             
                 // Creates a speech recognizer using microphone as audio input. Default language: en-us
                 using (var recognizer = new SpeechRecognizer(config))
                 {
                     Console.WriteLine("Say something...");
             
                     // Starts speech recognition, and returns after a single utterance is recognized. 
                     // The end of a single utterance is determined by listening for silence at the end 
                     // or until a timeout period has elapsed.  The task returns the
                     // recognition text as result.
                     //
                     // Note: Since RecognizeOnceAsync() returns only a single utterance, 
                     // it is suitable only for single shot recognition like command or query.
                     // For long-running multi-utterance recognition, 
                     // use StartContinuousRecognitionAsync() instead.
             
                     var result = await recognizer.RecognizeOnceAsync();
             
                     // Checks result.
                     if (result.Reason == ResultReason.RecognizedSpeech)
                     {
                         Console.WriteLine($"RECOGNIZED: Text={result.Text}");
                     }
                     else if (result.Reason == ResultReason.NoMatch)
                     {
                         Console.WriteLine($"NOMATCH: Speech could not be recognized.");
                     }
                     else if (result.Reason == ResultReason.Canceled)
                     {
                         var cancellation = CancellationDetails.FromResult(result);
                         Console.WriteLine($"CANCELED: Reason={cancellation.Reason}");
             
                         if (cancellation.Reason == CancellationReason.Error)
                         {
                             Console.WriteLine($"CANCELED: ErrorCode={cancellation.ErrorCode}");
                             Console.WriteLine($"CANCELED: ErrorDetails={cancellation.ErrorDetails}");
                             Console.WriteLine($"CANCELED: Did you update the subscription info?");
                         }
                     }
                 }
             }
             </code></example>
      </Docs>
    </Member>
    <Member MemberName="Recognizing">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognizing;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognizing" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognizing" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event Recognizing As EventHandler(Of SpeechRecognitionEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Recognizing : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " Usage="member this.Recognizing : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognizing" /> signals that an intermediate recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionLanguage">
      <MemberSignature Language="C#" Value="public string SpeechRecognitionLanguage { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string SpeechRecognitionLanguage" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.SpeechRecognitionLanguage" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property SpeechRecognitionLanguage As String" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionLanguage : string" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.SpeechRecognitionLanguage" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the language name that was set when the recognizer was created.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StartContinuousRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StartContinuousRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StartContinuousRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartContinuousRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StartContinuousRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StartContinuousRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StartContinuousRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Starts speech recognition on a continuous audio stream as an asynchronous operation, until StopContinuousRecognitionAsync() is called.
            You must subscribe to events to receive recognition results.
            </summary>
        <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        <remarks>
            See also: [Continuous recognition](/azure/cognitive-services/speech-service/get-started-speech-to-text?tabs=windowsinstall)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartKeywordRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StartKeywordRecognitionAsync (Microsoft.CognitiveServices.Speech.KeywordRecognitionModel model);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StartKeywordRecognitionAsync(class Microsoft.CognitiveServices.Speech.KeywordRecognitionModel model) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartKeywordRecognitionAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)" />
      <MemberSignature Language="VB.NET" Value="Public Function StartKeywordRecognitionAsync (model As KeywordRecognitionModel) As Task" />
      <MemberSignature Language="F#" Value="member this.StartKeywordRecognitionAsync : Microsoft.CognitiveServices.Speech.KeywordRecognitionModel -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StartKeywordRecognitionAsync model" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="Microsoft.CognitiveServices.Speech.KeywordRecognitionModel" />
      </Parameters>
      <Docs>
        <param name="model">The keyword recognition model that specifies the keyword to be recognized.</param>
        <summary>
            Configures the recognizer with the given keyword model. After calling this method, the recognizer is listening 
            for the keyword to start the recognition. Call StopKeywordRecognitionAsync() to end the keyword initiated recognition.
            You must subscribe to events to receive recognition results.
            </summary>
        <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        <remarks>
            See also: [Use a keyword model with the SDK](/azure/cognitive-services/speech-service/custom-keyword-basics?pivots=programming-language-csharp#use-a-keyword-model-with-the-sdk)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName="StopContinuousRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StopContinuousRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StopContinuousRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StopContinuousRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StopContinuousRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StopContinuousRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StopContinuousRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Stops a running recognition operation as soon as possible and immediately requests a result based on the
            the input that has been processed so far. This works for all recognition operations, not just continuous
            ones, and facilitates the use of push-to-talk or "finish now" buttons for manual audio endpointing.
            </summary>
        <returns>
            A task that will complete when input processing has been stopped. Result generation, if applicable for the
            input provided, may happen after this task completes and should be handled with the appropriate event.
            </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StopKeywordRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StopKeywordRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StopKeywordRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StopKeywordRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StopKeywordRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StopKeywordRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StopKeywordRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Ends the keyword initiated recognition.
            </summary>
        <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        <remarks>
            Note: Keyword recognition features might work with any microphone type, but official support is currently
            limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
