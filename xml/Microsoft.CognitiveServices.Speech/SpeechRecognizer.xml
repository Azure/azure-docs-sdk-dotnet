<Type Name="SpeechRecognizer" FullName="Microsoft.CognitiveServices.Speech.SpeechRecognizer">
  <TypeSignature Language="C#" Value="public sealed class SpeechRecognizer : Microsoft.CognitiveServices.Speech.Recognizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit SpeechRecognizer extends Microsoft.CognitiveServices.Speech.Recognizer" />
  <TypeSignature Language="DocId" Value="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class SpeechRecognizer&#xA;Inherits Recognizer" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    inherit Recognizer" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
    <AssemblyVersion>0.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.CognitiveServices.Speech.Recognizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
             Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.
             </summary>
    <remarks>To be added.</remarks>
    <example>
             An example to use the speech recognizer from microphone and listen to events generated by the recognizer.
             <code>
             public async Task SpeechContinuousRecognitionAsync()
             {
                 // Creates an instance of a speech factory with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var factory = SpeechFactory.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer from microphone.
                 using (var recognizer = factory.CreateSpeechRecognizer())
                 {
                     // Subscribes to events.
                     recognizer.IntermediateResultReceived += (s, e) =&gt; {
                         Console.WriteLine($"\n    Partial result: {e.Result.Text}.");
                     };
            
                     recognizer.FinalResultReceived += (s, e) =&gt; {
                         var result = e.Result;
                         Console.WriteLine($"Recognition status: {result.RecognitionStatus.ToString()}");
                         if (result.RecognitionStatus == RecognitionStatus.Recognized)
                         {
                                 Console.WriteLine($"Final result: Text: {result.Text}."); 
                         }
                     };
            
                     recognizer.RecognitionErrorRaised += (s, e) =&gt; {
                         Console.WriteLine($"\n    An error occurred. Status: {e.Status.ToString()}, FailureReason: {e.FailureReason}");
                     };
            
                     recognizer.OnSessionEvent += (s, e) =&gt; {
                         Console.WriteLine($"\n    Session event. Event: {e.EventType.ToString()}.");
                     };
            
                     // Starts continuous recognition. Uses StopContinuousRecognitionAsync() to stop recognition.
                     await recognizer.StartContinuousRecognitionAsync().ConfigureAwait(false);
            
                     do
                     {
                         Console.WriteLine("Press Enter to stop");
                     } while (Console.ReadKey().Key != ConsoleKey.Enter);
            
                     // Stops recognition.
                     await recognizer.StopContinuousRecognitionAsync().ConfigureAwait(false);
                 }
             }
             </code></example>
    <example>
             An example to use the speech recognizer from microphone and listen to events generated by the recognizer.
             <code>
             public async Task SpeechContinuousRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer from microphone.
                 using (var recognizer = new SpeechRecognizer(config))
                 {
                     // Subscribes to events.
                     recognizer.Recognizing += (s, e) =&gt; {
                         Console.WriteLine($"RECOGNIZING: Text={e.Result.Text}");
                     };
            
                     recognizer.Recognized += (s, e) =&gt; {
                         var result = e.Result;
                         Console.WriteLine($"Reason: {result.Reason.ToString()}");
                         if (result.Reason == ResultReason.RecognizedSpeech)
                         {
                                 Console.WriteLine($"Final result: Text: {result.Text}."); 
                         }
                     };
            
                     recognizer.Canceled += (s, e) =&gt; {
                         Console.WriteLine($"\n    Recognition Canceled. Reason: {e.Reason.ToString()}, CanceledReason: {e.Reason}");
                     };
            
                     recognizer.SessionStarted += (s, e) =&gt; {
                         Console.WriteLine("\n    Session started event.");
                     };
            
                     recognizer.SessionStopped += (s, e) =&gt; {
                         Console.WriteLine("\n    Session stopped event.");
                     };
            
                     // Starts continuous recognition. Uses StopContinuousRecognitionAsync() to stop recognition.
                     await recognizer.StartContinuousRecognitionAsync().ConfigureAwait(false);
            
                     do
                     {
                         Console.WriteLine("Press Enter to stop");
                     } while (Console.ReadKey().Key != ConsoleKey.Enter);
            
                     // Stops recognition.
                     await recognizer.StopContinuousRecognitionAsync().ConfigureAwait(false);
                 }
             }
             </code></example>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer speechConfig" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SpeechRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SpeechRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SpeechRecognizer (speechConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SpeechRecognizer.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AuthorizationToken">
      <MemberSignature Language="C#" Value="public string AuthorizationToken { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string AuthorizationToken" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken" />
      <MemberSignature Language="VB.NET" Value="Public Property AuthorizationToken As String" />
      <MemberSignature Language="F#" Value="member this.AuthorizationToken : string with get, set" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets/sets authorization token used to communicate with the service.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Canceled">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; Canceled;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; Canceled" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Canceled" />
      <MemberSignature Language="VB.NET" Value="Public Event Canceled As EventHandler(Of SpeechRecognitionCanceledEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Canceled : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; " Usage="member this.Canceled : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Canceled" /> signals that the speech recognition was canceled.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="DeploymentId">
      <MemberSignature Language="C#" Value="public string DeploymentId { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string DeploymentId" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.DeploymentId" />
      <MemberSignature Language="VB.NET" Value="Public Property DeploymentId As String" />
      <MemberSignature Language="F#" Value="member this.DeploymentId : string with get, set" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.DeploymentId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets/sets the deployment id of a customized speech model that is used for speech recognition.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected override void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overrides Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="F#" Value="override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">To be added.</param>
        <summary>To be added.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="EndpointId">
      <MemberSignature Language="C#" Value="public string EndpointId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string EndpointId" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.EndpointId" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property EndpointId As String" />
      <MemberSignature Language="F#" Value="member this.EndpointId : string" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.EndpointId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the endpoint ID of a customized speech model that is used for speech recognition.
            </summary>
        <value>the endpoint ID of a customized speech model that is used for speech recognition</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="FinalResultReceived">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; FinalResultReceived;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; FinalResultReceived" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.FinalResultReceived" />
      <MemberSignature Language="VB.NET" Value="Public Event FinalResultReceived As EventHandler(Of SpeechRecognitionResultEventArgs) " />
      <MemberSignature Language="F#" Value="member this.FinalResultReceived : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; " Usage="member this.FinalResultReceived : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.FinalResultReceived" /> signals that a final recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="IntermediateResultReceived">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; IntermediateResultReceived;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; IntermediateResultReceived" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.IntermediateResultReceived" />
      <MemberSignature Language="VB.NET" Value="Public Event IntermediateResultReceived As EventHandler(Of SpeechRecognitionResultEventArgs) " />
      <MemberSignature Language="F#" Value="member this.IntermediateResultReceived : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; " Usage="member this.IntermediateResultReceived : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResultEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.IntermediateResultReceived" /> signals that an intermediate recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Language">
      <MemberSignature Language="C#" Value="public string Language { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Language" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Language" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Language As String" />
      <MemberSignature Language="F#" Value="member this.Language : string" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.Language" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the language name that was set when the recognizer was created.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputFormat">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.OutputFormat OutputFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype Microsoft.CognitiveServices.Speech.OutputFormat OutputFormat" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.OutputFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property OutputFormat As OutputFormat" />
      <MemberSignature Language="F#" Value="member this.OutputFormat : Microsoft.CognitiveServices.Speech.OutputFormat" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.OutputFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.OutputFormat</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the output format setting.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Parameters">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.IRecognizerParameters Parameters { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Microsoft.CognitiveServices.Speech.IRecognizerParameters Parameters" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Parameters" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Parameters As IRecognizerParameters" />
      <MemberSignature Language="F#" Value="member this.Parameters : Microsoft.CognitiveServices.Speech.IRecognizerParameters" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.Parameters" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.IRecognizerParameters</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The collection of parameters and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer" />.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Properties">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.PropertyCollection Properties { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Microsoft.CognitiveServices.Speech.PropertyCollection Properties" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Properties" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Properties As PropertyCollection" />
      <MemberSignature Language="F#" Value="member this.Properties : Microsoft.CognitiveServices.Speech.PropertyCollection" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.Properties" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyCollection</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The collection or properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer" />.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RecognitionErrorRaised">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.RecognitionErrorEventArgs&gt; RecognitionErrorRaised;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.RecognitionErrorEventArgs&gt; RecognitionErrorRaised" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.RecognitionErrorRaised" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognitionErrorRaised As EventHandler(Of RecognitionErrorEventArgs) " />
      <MemberSignature Language="F#" Value="member this.RecognitionErrorRaised : EventHandler&lt;Microsoft.CognitiveServices.Speech.RecognitionErrorEventArgs&gt; " Usage="member this.RecognitionErrorRaised : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.RecognitionErrorEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.RecognitionErrorEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.RecognitionErrorRaised" /> signals that an error occurred during recognition.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RecognizeAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.RecognizeAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function RecognizeAsync () As Task(Of SpeechRecognitionResult)" />
      <MemberSignature Language="F#" Value="member this.RecognizeAsync : unit -&gt; System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;" Usage="speechRecognizer.RecognizeAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
             Starts speech recognition, and stops after the first utterance is recognized. The task returns the recognition text as result.
             Note: RecognizeAsync() returns when the first utterance has been recognized, so it is suitable only for single shot recognition like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
             </summary>
        <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult" /></returns>
        <remarks>To be added.</remarks>
        <example>
             The following example creates a speech recognizer, and then gets and prints the recognition result.
             <code>
             public async Task SpeechSingleShotRecognitionAsync()
             {
                 // Creates an instance of a speech factory with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var factory = SpeechFactory.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer using microphone as audio input. The default language is "en-us".
                 using (var recognizer = factory.CreateSpeechRecognizer())
                 {
                     // Starts recognizing.
                     Console.WriteLine("Say something...");
            
                     // Performs recognition.
                     // RecognizeAsync() returns when the first utterance has been recognized, so it is suitable 
                     // only for single shot recognition like command or query. For long-running recognition, use
                     // StartContinuousRecognitionAsync() instead.
                     var result = await recognizer.RecognizeAsync().ConfigureAwait(false);
            
                     // Checks result.
                     if (result.RecognitionStatus != RecognitionStatus.Recognized)
                     {
                         Console.WriteLine($"Recognition status: {result.RecognitionStatus.ToString()}");
                         if (result.RecognitionStatus == RecognitionStatus.Canceled)
                         {
                             Console.WriteLine($"There was an error, reason: {result.RecognitionFailureReason}");
                         }
                         else
                         {
                             Console.WriteLine("No speech could be recognized.\n");
                         }
                     }
                     else
                     {
                         Console.WriteLine($"We recognized: {result.Text}");
                     }
                 }
             }
             </code></example>
      </Docs>
    </Member>
    <Member MemberName="Recognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognized" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognized" />
      <MemberSignature Language="VB.NET" Value="Public Event Recognized As EventHandler(Of SpeechRecognitionEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Recognized : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " Usage="member this.Recognized : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognized" /> signals that a final recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RecognizeOnceAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeOnceAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeOnceAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.RecognizeOnceAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function RecognizeOnceAsync () As Task(Of SpeechRecognitionResult)" />
      <MemberSignature Language="F#" Value="member this.RecognizeOnceAsync : unit -&gt; System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;" Usage="speechRecognizer.RecognizeOnceAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
             Starts speech recognition, and stops after the first utterance is recognized. The task returns the recognition text as result.
             Note: RecognizeOnceAsync() returns when the first utterance has been recognized, so it is suitable only for single shot recognition like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
             </summary>
        <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult" /></returns>
        <remarks>To be added.</remarks>
        <example>
             The following example creates a speech recognizer, and then gets and prints the recognition result.
             <code>
             public async Task SpeechSingleShotRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer using microphone as audio input. The default language is "en-us".
                 using (var recognizer = new SpeechRecognizer(config))
                 {
                     Console.WriteLine("Say something...");
            
                     // Performs recognition. RecognizeOnceAsync() returns when the first utterance has been recognized,
                     // so it is suitable only for single shot recognition like command or query. For long-running
                     // recognition, use StartContinuousRecognitionAsync() instead.
                     var result = await recognizer.RecognizeOnceAsync();
            
                     // Checks result.
                     if (result.Reason == ResultReason.RecognizedSpeech)
                     {
                         Console.WriteLine($"RECOGNIZED: Text={result.Text}");
                     }
                     else if (result.Reason == ResultReason.NoMatch)
                     {
                         Console.WriteLine($"NOMATCH: Speech could not be recognized.");
                     }
                     else if (result.Reason == ResultReason.Canceled)
                     {
                         var cancellation = CancellationDetails.FromResult(result);
                         Console.WriteLine($"CANCELED: Reason={cancellation.Reason}");
            
                         if (cancellation.Reason == CancellationReason.Error)
                         {
                             Console.WriteLine($"CANCELED: ErrorDetails={cancellation.ErrorDetails}");
                             Console.WriteLine($"CANCELED: Did you update the subscription info?");
                         }
                     }
                 }
             }
             </code></example>
      </Docs>
    </Member>
    <Member MemberName="Recognizing">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognizing;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognizing" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognizing" />
      <MemberSignature Language="VB.NET" Value="Public Event Recognizing As EventHandler(Of SpeechRecognitionEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Recognizing : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " Usage="member this.Recognizing : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognizing" /> signals that an intermediate recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionLanguage">
      <MemberSignature Language="C#" Value="public string SpeechRecognitionLanguage { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string SpeechRecognitionLanguage" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.SpeechRecognitionLanguage" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property SpeechRecognitionLanguage As String" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionLanguage : string" Usage="Microsoft.CognitiveServices.Speech.SpeechRecognizer.SpeechRecognitionLanguage" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the language name that was set when the recognizer was created.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StartContinuousRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StartContinuousRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StartContinuousRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartContinuousRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StartContinuousRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StartContinuousRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StartContinuousRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Starts speech recognition on a continuous audio stream, until StopContinuousRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
        <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StartKeywordRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StartKeywordRecognitionAsync (Microsoft.CognitiveServices.Speech.KeywordRecognitionModel model);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StartKeywordRecognitionAsync(class Microsoft.CognitiveServices.Speech.KeywordRecognitionModel model) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartKeywordRecognitionAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)" />
      <MemberSignature Language="VB.NET" Value="Public Function StartKeywordRecognitionAsync (model As KeywordRecognitionModel) As Task" />
      <MemberSignature Language="F#" Value="member this.StartKeywordRecognitionAsync : Microsoft.CognitiveServices.Speech.KeywordRecognitionModel -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StartKeywordRecognitionAsync model" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="Microsoft.CognitiveServices.Speech.KeywordRecognitionModel" />
      </Parameters>
      <Docs>
        <param name="model">The keyword recognition model that specifies the keyword to be recognized.</param>
        <summary>
            Starts speech recognition on a continuous audio stream with keyword spotting, until StopKeywordRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            Note: Keyword spotting functionality is only available on the Cognitive Services Device SDK. This functionality is currently not included in the SDK itself.
            </summary>
        <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StopContinuousRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StopContinuousRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StopContinuousRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StopContinuousRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StopContinuousRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StopContinuousRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StopContinuousRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Stops continuous speech recognition.
            </summary>
        <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StopKeywordRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StopKeywordRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StopKeywordRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StopKeywordRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StopKeywordRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StopKeywordRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="speechRecognizer.StopKeywordRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Stops continuous speech recognition with keyword spotting.
            Note: Key word spotting functionality is only available on the Cognitive Services Device SDK. This functionality is currently not included in the SDK itself.
            </summary>
        <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>