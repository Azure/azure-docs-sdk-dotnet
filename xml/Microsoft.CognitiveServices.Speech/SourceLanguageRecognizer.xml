<Type Name="SourceLanguageRecognizer" FullName="Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer">
  <TypeSignature Language="C#" Value="public sealed class SourceLanguageRecognizer : Microsoft.CognitiveServices.Speech.Recognizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit SourceLanguageRecognizer extends Microsoft.CognitiveServices.Speech.Recognizer" />
  <TypeSignature Language="DocId" Value="T:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class SourceLanguageRecognizer&#xA;Inherits Recognizer" />
  <TypeSignature Language="F#" Value="type SourceLanguageRecognizer = class&#xA;    inherit Recognizer" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
    <AssemblyVersion>1.17.0.28</AssemblyVersion>
    <AssemblyVersion>1.18.0.28</AssemblyVersion>
    <AssemblyVersion>1.19.0.28</AssemblyVersion>
    <AssemblyVersion>1.20.0.28</AssemblyVersion>
    <AssemblyVersion>1.21.0.28</AssemblyVersion>
    <AssemblyVersion>1.22.0.28</AssemblyVersion>
    <AssemblyVersion>1.23.0.28</AssemblyVersion>
    <AssemblyVersion>1.24.0.28</AssemblyVersion>
    <AssemblyVersion>1.24.1.28</AssemblyVersion>
    <AssemblyVersion>1.25.1.26</AssemblyVersion>
    <AssemblyVersion>1.27.0.28</AssemblyVersion>
    <AssemblyVersion>1.28.0.28</AssemblyVersion>
    <AssemblyVersion>1.30.0.28</AssemblyVersion>
    <AssemblyVersion>1.31.0.28</AssemblyVersion>
    <AssemblyVersion>1.32.1.28</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.CognitiveServices.Speech.Recognizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
            Detects the spoken language on the input audio.
            Added in version 1.17.0
            </summary>
    <remarks>
            See [Language Identification](https://aka.ms/speech/lid?pivots=programming-language-csharp) document.
            </remarks>
    <example>
             This example uses the source language recognizer from a microphone and receives events generated by the recognizer.
             <code language="c#">
             public async Task SourceLanguageContinuousRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
                 config.SetProperty(PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority, "Latency");
            
                 // Creates a source language recognizer from microphone.
                 using (var sourceLanguageRecognizer = new SourceLanguageRecognizer(config))
                 {
                     sourceLanguageRecognizer.Recognized += (s, e) =&gt; {
                         var result = e.Result;
                         Console.WriteLine($"Reason: {result.Reason.ToString()}");
                         if (result.Reason == ResultReason.RecognizedSpeech)
                         {
                             var lidResult = AutoDetectSourceLanguageResult.FromResult(e.Result);
                             Console.WriteLine($"RECOGNIZED: Language={lidResult.Language}");
                         }
                     };
            
                     sourceLanguageRecognizer.Canceled += (s, e) =&gt; {
                         Console.WriteLine($"\n    Canceled. Reason: {e.Reason.ToString()}, CanceledReason: {e.Reason}");
                     };
            
                     sourceLanguageRecognizer.SessionStarted += (s, e) =&gt; {
                         Console.WriteLine("\n    Session started event.");
                     };
            
                     sourceLanguageRecognizer.SessionStopped += (s, e) =&gt; {
                         Console.WriteLine("\n    Session stopped event.");
                     };
            
                     // Starts continuous recognition. 
                     // Uses StopContinuousRecognitionAsync() to stop recognition.
                     await sourceLanguageRecognizer.StartContinuousRecognitionAsync().ConfigureAwait(false);
            
                     do
                     {
                         Console.WriteLine("Press Enter to stop");
                     } while (Console.ReadKey().Key != ConsoleKey.Enter);
            
                     // Stops recognition.
                     await sourceLanguageRecognizer.StopContinuousRecognitionAsync().ConfigureAwait(false);
                 }
             }
             </code></example>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SourceLanguageRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig -&gt; Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer (speechConfig, autoDetectSourceLanguageConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">Configuration that specifies the language(s) to look for in the source speech to synthesize</param>
        <summary>
            Creates a new instance of SourceLanguageRecognizer that determines the source language from a different languageId modes and priorities.
            </summary>
        <remarks>
            See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
            </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SourceLanguageRecognizer (Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Microsoft.CognitiveServices.Speech.SpeechConfig speechConfig, class Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig autoDetectSourceLanguageConfig, class Microsoft.CognitiveServices.Speech.Audio.AudioConfig audioConfig) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (speechConfig As SpeechConfig, autoDetectSourceLanguageConfig As AutoDetectSourceLanguageConfig, audioConfig As AudioConfig)" />
      <MemberSignature Language="F#" Value="new Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer : Microsoft.CognitiveServices.Speech.SpeechConfig * Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig * Microsoft.CognitiveServices.Speech.Audio.AudioConfig -&gt; Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer" Usage="new Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer (speechConfig, autoDetectSourceLanguageConfig, audioConfig)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="speechConfig" Type="Microsoft.CognitiveServices.Speech.SpeechConfig" />
        <Parameter Name="autoDetectSourceLanguageConfig" Type="Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig" />
        <Parameter Name="audioConfig" Type="Microsoft.CognitiveServices.Speech.Audio.AudioConfig" />
      </Parameters>
      <Docs>
        <param name="speechConfig">Speech configuration</param>
        <param name="autoDetectSourceLanguageConfig">An instance that specifies possible source languages in the speech.</param>
        <param name="audioConfig">Audio configuration</param>
        <summary>
            Creates a new instance of SourceLanguageRecognizer.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AuthorizationToken">
      <MemberSignature Language="C#" Value="public string AuthorizationToken { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string AuthorizationToken" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.AuthorizationToken" />
      <MemberSignature Language="VB.NET" Value="Public Property AuthorizationToken As String" />
      <MemberSignature Language="F#" Value="member this.AuthorizationToken : string with get, set" Usage="Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.AuthorizationToken" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets authorization token used to communicate with the service.
              
            Note: Your code needs to ensure that the authorization token is valid. Before the authorization token
            expires, your code needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will produce errors during recognition.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Canceled">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; Canceled;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; Canceled" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Canceled" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event Canceled As EventHandler(Of SpeechRecognitionCanceledEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Canceled : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; " Usage="member this.Canceled : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Canceled" /> signals that the speech to source language recognition was canceled.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected override void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overrides Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="F#" Value="override this.Dispose : bool -&gt; unit" Usage="sourceLanguageRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">True to dispose managed resources.</param>
        <summary>
            Disposes of the object.
            </summary>
        <returns />
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Finalize">
      <MemberSignature Language="C#" Value="~SourceLanguageRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Finalize() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Finalize" />
      <MemberSignature Language="VB.NET" Value="Finalize ()" />
      <MemberSignature Language="F#" Value="override this.Finalize : unit -&gt; unit" Usage="sourceLanguageRecognizer.Finalize " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>To be added.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputFormat">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.OutputFormat OutputFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype Microsoft.CognitiveServices.Speech.OutputFormat OutputFormat" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.OutputFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property OutputFormat As OutputFormat" />
      <MemberSignature Language="F#" Value="member this.OutputFormat : Microsoft.CognitiveServices.Speech.OutputFormat" Usage="Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.OutputFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.OutputFormat</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the output format setting.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Properties">
      <MemberSignature Language="C#" Value="public Microsoft.CognitiveServices.Speech.PropertyCollection Properties { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Microsoft.CognitiveServices.Speech.PropertyCollection Properties" />
      <MemberSignature Language="DocId" Value="P:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Properties" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Properties As PropertyCollection" />
      <MemberSignature Language="F#" Value="member this.Properties : Microsoft.CognitiveServices.Speech.PropertyCollection" Usage="Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Properties" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.CognitiveServices.Speech.PropertyCollection</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer" />.
            Note: The property collection is only valid until the recognizer owning this Properties is disposed or finalized.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Recognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; Recognized" />
      <MemberSignature Language="DocId" Value="E:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Recognized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event Recognized As EventHandler(Of SpeechRecognitionEventArgs) " />
      <MemberSignature Language="F#" Value="member this.Recognized : EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " Usage="member this.Recognized : System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.Recognized" /> signals that a final recognition result is received.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RecognizeOnceAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeOnceAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task`1&lt;class Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt; RecognizeOnceAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.RecognizeOnceAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function RecognizeOnceAsync () As Task(Of SpeechRecognitionResult)" />
      <MemberSignature Language="F#" Value="member this.RecognizeOnceAsync : unit -&gt; System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;" Usage="sourceLanguageRecognizer.RecognizeOnceAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Microsoft.CognitiveServices.Speech.SpeechRecognitionResult&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
             Starts source language recognition as an asynchronous operation.
             </summary>
        <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult" /></returns>
        <remarks>
             The end of a single utterance is determined by listening for silence at the end, or until a timeout period has elapsed.
             The task returns the recognized speech in **SpeechRecognitionResult.Text**.
               
             You can call **StopContinuousRecognitionAsync** to stop recognition before a phrase has been recognized.
               
             Since this method returns only a single utterance, it is suitable only for single shot recognition like command or query. 
             For long-running multi-utterance recognition, use **StartContinuousRecognitionAsync** instead.
            
             See also: [Automatic language detection for speech to text](/azure/cognitive-services/speech-service/how-to-automatic-language-detection?pivots=programming-language-csharp)
             </remarks>
        <example>
             The following example creates a source language recognizer, and then gets and prints the recognition result.
             <code language="c#">
             public async Task SingleLanguageIdRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
                 config.SetProperty(PropertyId.SpeechServiceConnection_SingleLanguageIdPriority, "Latency");
            
                 // Creates a speech recognizer using microphone as audio input. Default language: en-us
                 using (var sourceLanguageRecognizer = new SourceLanguageRecognizer(config))
                 {
                     Console.WriteLine("Say something...");
             
                     // Starts source language recognition, and returns after a single utterance is recognized. 
                     // The end of a single utterance is determined by listening for silence at the end 
                     // or until a timeout period has elapsed.  The task returns the
                     // recognition text as result.
                     //
                     // Note: Since RecognizeOnceAsync() returns only a single utterance, 
                     // it is suitable only for single shot recognition like command or query.
                     // For long-running multi-utterance recognition, 
                     // use StartContinuousRecognitionAsync() instead.
             
                     var result = await sourceLanguageRecognizer.RecognizeOnceAsync();
             
                     // Checks result.
                     if (result.Reason == ResultReason.RecognizedSpeech)
                     {
                         var lidResult = AutoDetectSourceLanguageResult.FromResult(e.Result);
                         Console.WriteLine($"RECOGNIZED: Language={lidResult.Language}");
                     }
                     else if (result.Reason == ResultReason.NoMatch)
                     {
                         Console.WriteLine($"NOMATCH: Speech could not be recognized.");
                     }
                     else if (result.Reason == ResultReason.Canceled)
                     {
                         var cancellation = CancellationDetails.FromResult(result);
                         Console.WriteLine($"CANCELED: Reason={cancellation.Reason}");
             
                         if (cancellation.Reason == CancellationReason.Error)
                         {
                             Console.WriteLine($"CANCELED: ErrorCode={cancellation.ErrorCode}");
                             Console.WriteLine($"CANCELED: ErrorDetails={cancellation.ErrorDetails}");
                             Console.WriteLine($"CANCELED: Did you update the subscription info?");
                         }
                     }
                 }
             }
             </code></example>
      </Docs>
    </Member>
    <Member MemberName="StartContinuousRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StartContinuousRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StartContinuousRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.StartContinuousRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StartContinuousRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StartContinuousRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="sourceLanguageRecognizer.StartContinuousRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Starts source language recognition on a continuous audio stream, until StopContinuousRecognitionAsync() is called.
            You must subscribe to events to receive recognition results.
            </summary>
        <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="StopContinuousRecognitionAsync">
      <MemberSignature Language="C#" Value="public System.Threading.Tasks.Task StopContinuousRecognitionAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Threading.Tasks.Task StopContinuousRecognitionAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.CognitiveServices.Speech.SourceLanguageRecognizer.StopContinuousRecognitionAsync" />
      <MemberSignature Language="VB.NET" Value="Public Function StopContinuousRecognitionAsync () As Task" />
      <MemberSignature Language="F#" Value="member this.StopContinuousRecognitionAsync : unit -&gt; System.Threading.Tasks.Task" Usage="sourceLanguageRecognizer.StopContinuousRecognitionAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.CognitiveServices.Speech.csharp</AssemblyName>
        <AssemblyVersion>1.32.1.28</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Stops a running recognition operation as soon as possible and immediately requests a result based on the
            the input that has been processed so far. This works for all recognition operations, not just continuous
            ones, and facilitates the use of push-to-talk or "finish now" buttons for manual audio endpointing.
            </summary>
        <returns>
            A task that will complete when input processing has been stopped. Result generation, if applicable for the
            input provided, may happen after this task completes and should be handled with the appropriate event.
            </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
