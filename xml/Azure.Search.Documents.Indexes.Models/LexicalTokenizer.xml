<Type Name="LexicalTokenizer" FullName="Azure.Search.Documents.Indexes.Models.LexicalTokenizer">
  <TypeSignature Language="C#" Value="public class LexicalTokenizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit LexicalTokenizer extends System.Object" />
  <TypeSignature Language="DocId" Value="T:Azure.Search.Documents.Indexes.Models.LexicalTokenizer" />
  <TypeSignature Language="VB.NET" Value="Public Class LexicalTokenizer" />
  <TypeSignature Language="F#" Value="type LexicalTokenizer = class" />
  <AssemblyInfo>
    <AssemblyName>Azure.Search.Documents</AssemblyName>
    <AssemblyVersion>11.2.0.0</AssemblyVersion>
    <AssemblyVersion>11.2.1.0</AssemblyVersion>
    <AssemblyVersion>11.3.0.0</AssemblyVersion>
    <AssemblyVersion>11.4.0.0</AssemblyVersion>
    <AssemblyVersion>11.5.0.0</AssemblyVersion>
    <AssemblyVersion>11.5.1.0</AssemblyVersion>
    <AssemblyVersion>11.6.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
            Base type for tokenizers.
            Please note <see cref="T:Azure.Search.Documents.Indexes.Models.LexicalTokenizer" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.Search.Documents.Indexes.Models.ClassicTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.EdgeNGramTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.KeywordTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.KeywordTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.MicrosoftLanguageStemmingTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.MicrosoftLanguageTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.NGramTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.PathHierarchyTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.PatternTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer" />, <see cref="T:Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer" /> and <see cref="T:Azure.Search.Documents.Indexes.Models.UaxUrlEmailTokenizer" />.
            </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="Name">
      <MemberSignature Language="C#" Value="public string Name { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Name" />
      <MemberSignature Language="DocId" Value="P:Azure.Search.Documents.Indexes.Models.LexicalTokenizer.Name" />
      <MemberSignature Language="VB.NET" Value="Public Property Name As String" />
      <MemberSignature Language="F#" Value="member this.Name : string with get, set" Usage="Azure.Search.Documents.Indexes.Models.LexicalTokenizer.Name" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.Search.Documents</AssemblyName>
        <AssemblyVersion>11.6.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary> The name of the tokenizer. It must only contain letters, digits, spaces, dashes or underscores, can only start and end with alphanumeric characters, and is limited to 128 characters. </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
