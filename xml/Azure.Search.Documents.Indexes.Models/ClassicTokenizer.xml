<Type Name="ClassicTokenizer" FullName="Azure.Search.Documents.Indexes.Models.ClassicTokenizer">
  <TypeSignature Language="C#" Value="public class ClassicTokenizer : Azure.Search.Documents.Indexes.Models.LexicalTokenizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit ClassicTokenizer extends Azure.Search.Documents.Indexes.Models.LexicalTokenizer" />
  <TypeSignature Language="DocId" Value="T:Azure.Search.Documents.Indexes.Models.ClassicTokenizer" />
  <TypeSignature Language="VB.NET" Value="Public Class ClassicTokenizer&#xA;Inherits LexicalTokenizer" />
  <TypeSignature Language="F#" Value="type ClassicTokenizer = class&#xA;    inherit LexicalTokenizer" />
  <AssemblyInfo>
    <AssemblyName>Azure.Search.Documents</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
    <AssemblyVersion>11.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Azure.Search.Documents.Indexes.Models.LexicalTokenizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary> Grammar-based tokenizer that is suitable for processing most European-language documents. This tokenizer is implemented using Apache Lucene. </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public ClassicTokenizer (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.Search.Documents.Indexes.Models.ClassicTokenizer.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (name As String)" />
      <MemberSignature Language="F#" Value="new Azure.Search.Documents.Indexes.Models.ClassicTokenizer : string -&gt; Azure.Search.Documents.Indexes.Models.ClassicTokenizer" Usage="new Azure.Search.Documents.Indexes.Models.ClassicTokenizer name" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.Search.Documents</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
        <AssemblyVersion>11.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name"> The name of the tokenizer. It must only contain letters, digits, spaces, dashes or underscores, can only start and end with alphanumeric characters, and is limited to 128 characters. </param>
        <summary> Initializes a new instance of ClassicTokenizer. </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="MaxTokenLength">
      <MemberSignature Language="C#" Value="public int? MaxTokenLength { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Nullable`1&lt;int32&gt; MaxTokenLength" />
      <MemberSignature Language="DocId" Value="P:Azure.Search.Documents.Indexes.Models.ClassicTokenizer.MaxTokenLength" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxTokenLength As Nullable(Of Integer)" />
      <MemberSignature Language="F#" Value="member this.MaxTokenLength : Nullable&lt;int&gt; with get, set" Usage="Azure.Search.Documents.Indexes.Models.ClassicTokenizer.MaxTokenLength" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.Search.Documents</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
        <AssemblyVersion>11.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Nullable&lt;System.Int32&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary> The maximum token length. Default is 255. Tokens longer than the maximum length are split. The maximum token length that can be used is 300 characters. </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
