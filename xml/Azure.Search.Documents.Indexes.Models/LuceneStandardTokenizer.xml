<Type Name="LuceneStandardTokenizer" FullName="Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer">
  <TypeSignature Language="C#" Value="public class LuceneStandardTokenizer : Azure.Search.Documents.Indexes.Models.LexicalTokenizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit LuceneStandardTokenizer extends Azure.Search.Documents.Indexes.Models.LexicalTokenizer" />
  <TypeSignature Language="DocId" Value="T:Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer" />
  <TypeSignature Language="VB.NET" Value="Public Class LuceneStandardTokenizer&#xA;Inherits LexicalTokenizer" />
  <TypeSignature Language="F#" Value="type LuceneStandardTokenizer = class&#xA;    inherit LexicalTokenizer" />
  <AssemblyInfo>
    <AssemblyName>Azure.Search.Documents</AssemblyName>
    <AssemblyVersion>11.2.0.0</AssemblyVersion>
    <AssemblyVersion>11.2.1.0</AssemblyVersion>
    <AssemblyVersion>11.3.0.0</AssemblyVersion>
    <AssemblyVersion>11.4.0.0</AssemblyVersion>
    <AssemblyVersion>11.5.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Azure.Search.Documents.Indexes.Models.LexicalTokenizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary> Breaks text following the Unicode Text Segmentation rules. This tokenizer is implemented using Apache Lucene. </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public LuceneStandardTokenizer (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (name As String)" />
      <MemberSignature Language="F#" Value="new Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer : string -&gt; Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer" Usage="new Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer name" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.Search.Documents</AssemblyName>
        <AssemblyVersion>11.4.0.0</AssemblyVersion>
        <AssemblyVersion>11.5.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">
            The name of the tokenizer. It must only contain letters, digits, spaces, dashes or underscores,
            can only start and end with alphanumeric characters, and is limited to 128 characters.
            </param>
        <summary>
            Initializes a new instance of LuceneStandardTokenizer.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="MaxTokenLength">
      <MemberSignature Language="C#" Value="public int? MaxTokenLength { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Nullable`1&lt;int32&gt; MaxTokenLength" />
      <MemberSignature Language="DocId" Value="P:Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer.MaxTokenLength" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxTokenLength As Nullable(Of Integer)" />
      <MemberSignature Language="F#" Value="member this.MaxTokenLength : Nullable&lt;int&gt; with get, set" Usage="Azure.Search.Documents.Indexes.Models.LuceneStandardTokenizer.MaxTokenLength" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.Search.Documents</AssemblyName>
        <AssemblyVersion>11.4.0.0</AssemblyVersion>
        <AssemblyVersion>11.5.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Nullable&lt;System.Int32&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            The maximum token length. Default is 255.
            Tokens longer than the maximum length are split.
            The maximum token length that can be used is 300 characters.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
