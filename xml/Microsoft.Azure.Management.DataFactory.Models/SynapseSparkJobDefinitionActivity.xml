<Type Name="SynapseSparkJobDefinitionActivity" FullName="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity">
  <TypeSignature Language="C#" Value="public class SynapseSparkJobDefinitionActivity : Microsoft.Azure.Management.DataFactory.Models.ExecutionActivity" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SynapseSparkJobDefinitionActivity extends Microsoft.Azure.Management.DataFactory.Models.ExecutionActivity" />
  <TypeSignature Language="DocId" Value="T:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity" />
  <TypeSignature Language="VB.NET" Value="Public Class SynapseSparkJobDefinitionActivity&#xA;Inherits ExecutionActivity" />
  <TypeSignature Language="F#" Value="type SynapseSparkJobDefinitionActivity = class&#xA;    inherit ExecutionActivity" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
    <AssemblyVersion>6.0.0.0</AssemblyVersion>
    <AssemblyVersion>7.0.0.0</AssemblyVersion>
    <AssemblyVersion>8.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.Azure.Management.DataFactory.Models.ExecutionActivity</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName Language="C#">[Microsoft.Rest.Serialization.JsonTransformation]</AttributeName>
      <AttributeName Language="F#">[&lt;Microsoft.Rest.Serialization.JsonTransformation&gt;]</AttributeName>
    </Attribute>
    <Attribute>
      <AttributeName Language="C#">[Newtonsoft.Json.JsonObject("SparkJob")]</AttributeName>
      <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonObject("SparkJob")&gt;]</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>
            Execute spark job activity.
            </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SynapseSparkJobDefinitionActivity ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>
            Initializes a new instance of the SynapseSparkJobDefinitionActivity
            class.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SynapseSparkJobDefinitionActivity (string name, Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference sparkJob, System.Collections.Generic.IDictionary&lt;string,object&gt; additionalProperties, string description, System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt; dependsOn, System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt; userProperties, Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference linkedServiceName, Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy policy, System.Collections.Generic.IList&lt;object&gt; arguments, object file, object className, System.Collections.Generic.IList&lt;object&gt; files, Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference targetBigDataPool, object executorSize = default, object conf = default, object driverSize = default, int? numExecutors = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string name, class Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference sparkJob, class System.Collections.Generic.IDictionary`2&lt;string, object&gt; additionalProperties, string description, class System.Collections.Generic.IList`1&lt;class Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt; dependsOn, class System.Collections.Generic.IList`1&lt;class Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt; userProperties, class Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference linkedServiceName, class Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy policy, class System.Collections.Generic.IList`1&lt;object&gt; arguments, object file, object className, class System.Collections.Generic.IList`1&lt;object&gt; files, class Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference targetBigDataPool, object executorSize, object conf, object driverSize, valuetype System.Nullable`1&lt;int32&gt; numExecutors) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.#ctor(System.String,Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference,System.Collections.Generic.IDictionary{System.String,System.Object},System.String,System.Collections.Generic.IList{Microsoft.Azure.Management.DataFactory.Models.ActivityDependency},System.Collections.Generic.IList{Microsoft.Azure.Management.DataFactory.Models.UserProperty},Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference,Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy,System.Collections.Generic.IList{System.Object},System.Object,System.Object,System.Collections.Generic.IList{System.Object},Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference,System.Object,System.Object,System.Object,System.Nullable{System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (name As String, sparkJob As SynapseSparkJobReference, additionalProperties As IDictionary(Of String, Object), description As String, dependsOn As IList(Of ActivityDependency), userProperties As IList(Of UserProperty), linkedServiceName As LinkedServiceReference, policy As ActivityPolicy, arguments As IList(Of Object), file As Object, className As Object, files As IList(Of Object), targetBigDataPool As BigDataPoolParametrizationReference, Optional executorSize As Object = Nothing, Optional conf As Object = Nothing, Optional driverSize As Object = Nothing, Optional numExecutors As Nullable(Of Integer) = Nothing)" />
      <MemberSignature Language="F#" Value="new Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity : string * Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference * System.Collections.Generic.IDictionary&lt;string, obj&gt; * string * System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt; * System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt; * Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference * Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy * System.Collections.Generic.IList&lt;obj&gt; * obj * obj * System.Collections.Generic.IList&lt;obj&gt; * Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference * obj * obj * obj * Nullable&lt;int&gt; -&gt; Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity" Usage="new Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity (name, sparkJob, additionalProperties, description, dependsOn, userProperties, linkedServiceName, policy, arguments, file, className, files, targetBigDataPool, executorSize, conf, driverSize, numExecutors)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="sparkJob" Type="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference" />
        <Parameter Name="additionalProperties" Type="System.Collections.Generic.IDictionary&lt;System.String,System.Object&gt;" />
        <Parameter Name="description" Type="System.String" />
        <Parameter Name="dependsOn" Type="System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt;" />
        <Parameter Name="userProperties" Type="System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt;" />
        <Parameter Name="linkedServiceName" Type="Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference" />
        <Parameter Name="policy" Type="Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy" />
        <Parameter Name="arguments" Type="System.Collections.Generic.IList&lt;System.Object&gt;" />
        <Parameter Name="file" Type="System.Object" />
        <Parameter Name="className" Type="System.Object" />
        <Parameter Name="files" Type="System.Collections.Generic.IList&lt;System.Object&gt;" />
        <Parameter Name="targetBigDataPool" Type="Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference" />
        <Parameter Name="executorSize" Type="System.Object" />
        <Parameter Name="conf" Type="System.Object" />
        <Parameter Name="driverSize" Type="System.Object" />
        <Parameter Name="numExecutors" Type="System.Nullable&lt;System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="name">Activity name.</param>
        <param name="sparkJob">Synapse spark job reference.</param>
        <param name="additionalProperties">Unmatched properties from the
            message are deserialized this collection</param>
        <param name="description">Activity description.</param>
        <param name="dependsOn">Activity depends on condition.</param>
        <param name="userProperties">Activity user properties.</param>
        <param name="linkedServiceName">Linked service reference.</param>
        <param name="policy">Activity policy.</param>
        <param name="arguments">User specified arguments to
            SynapseSparkJobDefinitionActivity.</param>
        <param name="file">The main file used for the job, which will
            override the 'file' of the spark job definition you provide. Type:
            string (or Expression with resultType string).</param>
        <param name="className">The fully-qualified identifier or the main
            class that is in the main definition file, which will override the
            'className' of the spark job definition you provide. Type: string
            (or Expression with resultType string).</param>
        <param name="files">Additional files used for reference in the main
            definition file, which will override the 'files' of the spark job
            definition you provide.</param>
        <param name="targetBigDataPool">The name of the big data pool which
            will be used to execute the spark batch job, which will override
            the 'targetBigDataPool' of the spark job definition you
            provide.</param>
        <param name="executorSize">Number of core and memory to be used for
            executors allocated in the specified Spark pool for the job, which
            will be used for overriding 'executorCores' and 'executorMemory' of
            the spark job definition you provide. Type: string (or Expression
            with resultType string).</param>
        <param name="conf">Spark configuration properties, which will
            override the 'conf' of the spark job definition you
            provide.</param>
        <param name="driverSize">Number of core and memory to be used for
            driver allocated in the specified Spark pool for the job, which
            will be used for overriding 'driverCores' and 'driverMemory' of the
            spark job definition you provide. Type: string (or Expression with
            resultType string).</param>
        <param name="numExecutors">Number of executors to launch for this
            job, which will override the 'numExecutors' of the spark job
            definition you provide.</param>
        <summary>
            Initializes a new instance of the SynapseSparkJobDefinitionActivity
            class.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SynapseSparkJobDefinitionActivity (string name, Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference sparkJob, System.Collections.Generic.IDictionary&lt;string,object&gt; additionalProperties = default, string description = default, System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt; dependsOn = default, System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt; userProperties = default, Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference linkedServiceName = default, Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy policy = default, System.Collections.Generic.IList&lt;object&gt; arguments = default, object file = default, object className = default, System.Collections.Generic.IList&lt;object&gt; files = default, System.Collections.Generic.IList&lt;object&gt; pythonCodeReference = default, System.Collections.Generic.IList&lt;object&gt; filesV2 = default, Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference targetBigDataPool = default, object executorSize = default, object conf = default, object driverSize = default, int? numExecutors = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string name, class Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference sparkJob, class System.Collections.Generic.IDictionary`2&lt;string, object&gt; additionalProperties, string description, class System.Collections.Generic.IList`1&lt;class Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt; dependsOn, class System.Collections.Generic.IList`1&lt;class Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt; userProperties, class Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference linkedServiceName, class Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy policy, class System.Collections.Generic.IList`1&lt;object&gt; arguments, object file, object className, class System.Collections.Generic.IList`1&lt;object&gt; files, class System.Collections.Generic.IList`1&lt;object&gt; pythonCodeReference, class System.Collections.Generic.IList`1&lt;object&gt; filesV2, class Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference targetBigDataPool, object executorSize, object conf, object driverSize, valuetype System.Nullable`1&lt;int32&gt; numExecutors) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.#ctor(System.String,Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference,System.Collections.Generic.IDictionary{System.String,System.Object},System.String,System.Collections.Generic.IList{Microsoft.Azure.Management.DataFactory.Models.ActivityDependency},System.Collections.Generic.IList{Microsoft.Azure.Management.DataFactory.Models.UserProperty},Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference,Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy,System.Collections.Generic.IList{System.Object},System.Object,System.Object,System.Collections.Generic.IList{System.Object},System.Collections.Generic.IList{System.Object},System.Collections.Generic.IList{System.Object},Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference,System.Object,System.Object,System.Object,System.Nullable{System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (name As String, sparkJob As SynapseSparkJobReference, Optional additionalProperties As IDictionary(Of String, Object) = Nothing, Optional description As String = Nothing, Optional dependsOn As IList(Of ActivityDependency) = Nothing, Optional userProperties As IList(Of UserProperty) = Nothing, Optional linkedServiceName As LinkedServiceReference = Nothing, Optional policy As ActivityPolicy = Nothing, Optional arguments As IList(Of Object) = Nothing, Optional file As Object = Nothing, Optional className As Object = Nothing, Optional files As IList(Of Object) = Nothing, Optional pythonCodeReference As IList(Of Object) = Nothing, Optional filesV2 As IList(Of Object) = Nothing, Optional targetBigDataPool As BigDataPoolParametrizationReference = Nothing, Optional executorSize As Object = Nothing, Optional conf As Object = Nothing, Optional driverSize As Object = Nothing, Optional numExecutors As Nullable(Of Integer) = Nothing)" />
      <MemberSignature Language="F#" Value="new Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity : string * Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference * System.Collections.Generic.IDictionary&lt;string, obj&gt; * string * System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt; * System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt; * Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference * Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy * System.Collections.Generic.IList&lt;obj&gt; * obj * obj * System.Collections.Generic.IList&lt;obj&gt; * System.Collections.Generic.IList&lt;obj&gt; * System.Collections.Generic.IList&lt;obj&gt; * Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference * obj * obj * obj * Nullable&lt;int&gt; -&gt; Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity" Usage="new Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity (name, sparkJob, additionalProperties, description, dependsOn, userProperties, linkedServiceName, policy, arguments, file, className, files, pythonCodeReference, filesV2, targetBigDataPool, executorSize, conf, driverSize, numExecutors)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="sparkJob" Type="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference" />
        <Parameter Name="additionalProperties" Type="System.Collections.Generic.IDictionary&lt;System.String,System.Object&gt;" />
        <Parameter Name="description" Type="System.String" />
        <Parameter Name="dependsOn" Type="System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.ActivityDependency&gt;" />
        <Parameter Name="userProperties" Type="System.Collections.Generic.IList&lt;Microsoft.Azure.Management.DataFactory.Models.UserProperty&gt;" />
        <Parameter Name="linkedServiceName" Type="Microsoft.Azure.Management.DataFactory.Models.LinkedServiceReference" />
        <Parameter Name="policy" Type="Microsoft.Azure.Management.DataFactory.Models.ActivityPolicy" />
        <Parameter Name="arguments" Type="System.Collections.Generic.IList&lt;System.Object&gt;" />
        <Parameter Name="file" Type="System.Object" />
        <Parameter Name="className" Type="System.Object" />
        <Parameter Name="files" Type="System.Collections.Generic.IList&lt;System.Object&gt;" />
        <Parameter Name="pythonCodeReference" Type="System.Collections.Generic.IList&lt;System.Object&gt;" />
        <Parameter Name="filesV2" Type="System.Collections.Generic.IList&lt;System.Object&gt;" />
        <Parameter Name="targetBigDataPool" Type="Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference" />
        <Parameter Name="executorSize" Type="System.Object" />
        <Parameter Name="conf" Type="System.Object" />
        <Parameter Name="driverSize" Type="System.Object" />
        <Parameter Name="numExecutors" Type="System.Nullable&lt;System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="name">Activity name.</param>
        <param name="sparkJob">Synapse spark job reference.</param>
        <param name="additionalProperties">Unmatched properties from the
            message are deserialized this collection</param>
        <param name="description">Activity description.</param>
        <param name="dependsOn">Activity depends on condition.</param>
        <param name="userProperties">Activity user properties.</param>
        <param name="linkedServiceName">Linked service reference.</param>
        <param name="policy">Activity policy.</param>
        <param name="arguments">User specified arguments to
            SynapseSparkJobDefinitionActivity.</param>
        <param name="file">The main file used for the job, which will
            override the 'file' of the spark job definition you provide. Type:
            string (or Expression with resultType string).</param>
        <param name="className">The fully-qualified identifier or the main
            class that is in the main definition file, which will override the
            'className' of the spark job definition you provide. Type: string
            (or Expression with resultType string).</param>
        <param name="files">(Deprecated. Please use pythonCodeReference and
            filesV2) Additional files used for reference in the main definition
            file, which will override the 'files' of the spark job definition
            you provide.</param>
        <param name="pythonCodeReference">Additional python code files used
            for reference in the main definition file, which will override the
            'pyFiles' of the spark job definition you provide.</param>
        <param name="filesV2">Additional files used for reference in the
            main definition file, which will override the 'jars' and 'files' of
            the spark job definition you provide.</param>
        <param name="targetBigDataPool">The name of the big data pool which
            will be used to execute the spark batch job, which will override
            the 'targetBigDataPool' of the spark job definition you
            provide.</param>
        <param name="executorSize">Number of core and memory to be used for
            executors allocated in the specified Spark pool for the job, which
            will be used for overriding 'executorCores' and 'executorMemory' of
            the spark job definition you provide. Type: string (or Expression
            with resultType string).</param>
        <param name="conf">Spark configuration properties, which will
            override the 'conf' of the spark job definition you
            provide.</param>
        <param name="driverSize">Number of core and memory to be used for
            driver allocated in the specified Spark pool for the job, which
            will be used for overriding 'driverCores' and 'driverMemory' of the
            spark job definition you provide. Type: string (or Expression with
            resultType string).</param>
        <param name="numExecutors">Number of executors to launch for this
            job, which will override the 'numExecutors' of the spark job
            definition you provide.</param>
        <summary>
            Initializes a new instance of the SynapseSparkJobDefinitionActivity
            class.
            </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Arguments">
      <MemberSignature Language="C#" Value="public System.Collections.Generic.IList&lt;object&gt; Arguments { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.Generic.IList`1&lt;object&gt; Arguments" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Arguments" />
      <MemberSignature Language="VB.NET" Value="Public Property Arguments As IList(Of Object)" />
      <MemberSignature Language="F#" Value="member this.Arguments : System.Collections.Generic.IList&lt;obj&gt; with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Arguments" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.args")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.args")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Collections.Generic.IList&lt;System.Object&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets user specified arguments to
            SynapseSparkJobDefinitionActivity.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ClassName">
      <MemberSignature Language="C#" Value="public object ClassName { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object ClassName" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.ClassName" />
      <MemberSignature Language="VB.NET" Value="Public Property ClassName As Object" />
      <MemberSignature Language="F#" Value="member this.ClassName : obj with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.ClassName" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.className")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.className")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets the fully-qualified identifier or the main class that
            is in the main definition file, which will override the 'className'
            of the spark job definition you provide. Type: string (or
            Expression with resultType string).
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Conf">
      <MemberSignature Language="C#" Value="public object Conf { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object Conf" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Conf" />
      <MemberSignature Language="VB.NET" Value="Public Property Conf As Object" />
      <MemberSignature Language="F#" Value="member this.Conf : obj with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Conf" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.conf")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.conf")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets spark configuration properties, which will override
            the 'conf' of the spark job definition you provide.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="DriverSize">
      <MemberSignature Language="C#" Value="public object DriverSize { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object DriverSize" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.DriverSize" />
      <MemberSignature Language="VB.NET" Value="Public Property DriverSize As Object" />
      <MemberSignature Language="F#" Value="member this.DriverSize : obj with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.DriverSize" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.driverSize")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.driverSize")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets number of core and memory to be used for driver
            allocated in the specified Spark pool for the job, which will be
            used for overriding 'driverCores' and 'driverMemory' of the spark
            job definition you provide. Type: string (or Expression with
            resultType string).
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ExecutorSize">
      <MemberSignature Language="C#" Value="public object ExecutorSize { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object ExecutorSize" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.ExecutorSize" />
      <MemberSignature Language="VB.NET" Value="Public Property ExecutorSize As Object" />
      <MemberSignature Language="F#" Value="member this.ExecutorSize : obj with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.ExecutorSize" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.executorSize")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.executorSize")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets number of core and memory to be used for executors
            allocated in the specified Spark pool for the job, which will be
            used for overriding 'executorCores' and 'executorMemory' of the
            spark job definition you provide. Type: string (or Expression with
            resultType string).
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="File">
      <MemberSignature Language="C#" Value="public object File { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object File" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.File" />
      <MemberSignature Language="VB.NET" Value="Public Property File As Object" />
      <MemberSignature Language="F#" Value="member this.File : obj with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.File" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.file")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.file")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets the main file used for the job, which will override
            the 'file' of the spark job definition you provide. Type: string
            (or Expression with resultType string).
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Files">
      <MemberSignature Language="C#" Value="public System.Collections.Generic.IList&lt;object&gt; Files { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.Generic.IList`1&lt;object&gt; Files" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Files" />
      <MemberSignature Language="VB.NET" Value="Public Property Files As IList(Of Object)" />
      <MemberSignature Language="F#" Value="member this.Files : System.Collections.Generic.IList&lt;obj&gt; with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Files" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.files")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.files")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Collections.Generic.IList&lt;System.Object&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets (Deprecated. Please use pythonCodeReference and
            filesV2) Additional files used for reference in the main definition
            file, which will override the 'files' of the spark job definition
            you provide.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="FilesV2">
      <MemberSignature Language="C#" Value="public System.Collections.Generic.IList&lt;object&gt; FilesV2 { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.Generic.IList`1&lt;object&gt; FilesV2" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.FilesV2" />
      <MemberSignature Language="VB.NET" Value="Public Property FilesV2 As IList(Of Object)" />
      <MemberSignature Language="F#" Value="member this.FilesV2 : System.Collections.Generic.IList&lt;obj&gt; with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.FilesV2" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.filesV2")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.filesV2")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Collections.Generic.IList&lt;System.Object&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets additional files used for reference in the main
            definition file, which will override the 'jars' and 'files' of the
            spark job definition you provide.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="NumExecutors">
      <MemberSignature Language="C#" Value="public int? NumExecutors { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Nullable`1&lt;int32&gt; NumExecutors" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.NumExecutors" />
      <MemberSignature Language="VB.NET" Value="Public Property NumExecutors As Nullable(Of Integer)" />
      <MemberSignature Language="F#" Value="member this.NumExecutors : Nullable&lt;int&gt; with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.NumExecutors" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.numExecutors")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.numExecutors")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Nullable&lt;System.Int32&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets number of executors to launch for this job, which will
            override the 'numExecutors' of the spark job definition you
            provide.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="PythonCodeReference">
      <MemberSignature Language="C#" Value="public System.Collections.Generic.IList&lt;object&gt; PythonCodeReference { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.Generic.IList`1&lt;object&gt; PythonCodeReference" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.PythonCodeReference" />
      <MemberSignature Language="VB.NET" Value="Public Property PythonCodeReference As IList(Of Object)" />
      <MemberSignature Language="F#" Value="member this.PythonCodeReference : System.Collections.Generic.IList&lt;obj&gt; with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.PythonCodeReference" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.pythonCodeReference")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.pythonCodeReference")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Collections.Generic.IList&lt;System.Object&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets additional python code files used for reference in the
            main definition file, which will override the 'pyFiles' of the
            spark job definition you provide.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SparkJob">
      <MemberSignature Language="C#" Value="public Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference SparkJob { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference SparkJob" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.SparkJob" />
      <MemberSignature Language="VB.NET" Value="Public Property SparkJob As SynapseSparkJobReference" />
      <MemberSignature Language="F#" Value="member this.SparkJob : Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.SparkJob" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.sparkJob")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.sparkJob")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobReference</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets synapse spark job reference.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="TargetBigDataPool">
      <MemberSignature Language="C#" Value="public Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference TargetBigDataPool { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference TargetBigDataPool" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.TargetBigDataPool" />
      <MemberSignature Language="VB.NET" Value="Public Property TargetBigDataPool As BigDataPoolParametrizationReference" />
      <MemberSignature Language="F#" Value="member this.TargetBigDataPool : Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference with get, set" Usage="Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.TargetBigDataPool" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.targetBigDataPool")]</AttributeName>
          <AttributeName Language="F#">[&lt;Newtonsoft.Json.JsonProperty(PropertyName="typeProperties.targetBigDataPool")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Microsoft.Azure.Management.DataFactory.Models.BigDataPoolParametrizationReference</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets or sets the name of the big data pool which will be used to
            execute the spark batch job, which will override the
            'targetBigDataPool' of the spark job definition you provide.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Validate">
      <MemberSignature Language="C#" Value="public override void Validate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig virtual instance void Validate() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Azure.Management.DataFactory.Models.SynapseSparkJobDefinitionActivity.Validate" />
      <MemberSignature Language="VB.NET" Value="Public Overrides Sub Validate ()" />
      <MemberSignature Language="F#" Value="override this.Validate : unit -&gt; unit" Usage="synapseSparkJobDefinitionActivity.Validate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Azure.Management.DataFactory</AssemblyName>
        <AssemblyVersion>8.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
            Validate the object.
            </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown if validation fails
            </exception>
      </Docs>
    </Member>
  </Members>
</Type>
