<Type Name="EmbeddingsClient" FullName="Azure.AI.Inference.EmbeddingsClient">
  <TypeSignature Language="C#" Value="public class EmbeddingsClient" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit EmbeddingsClient extends System.Object" />
  <TypeSignature Language="DocId" Value="T:Azure.AI.Inference.EmbeddingsClient" />
  <TypeSignature Language="VB.NET" Value="Public Class EmbeddingsClient" />
  <TypeSignature Language="F#" Value="type EmbeddingsClient = class" />
  <AssemblyInfo>
    <AssemblyName>Azure.AI.Inference</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary> The Embeddings service client. </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="protected EmbeddingsClient ();" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.#ctor" />
      <MemberSignature Language="VB.NET" Value="Protected Sub New ()" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary> Initializes a new instance of EmbeddingsClient for mocking. </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public EmbeddingsClient (Uri endpoint, Azure.AzureKeyCredential credential);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.AzureKeyCredential credential) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.AzureKeyCredential)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As AzureKeyCredential)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.EmbeddingsClient : Uri * Azure.AzureKeyCredential -&gt; Azure.AI.Inference.EmbeddingsClient" Usage="new Azure.AI.Inference.EmbeddingsClient (endpoint, credential)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.AzureKeyCredential" />
      </Parameters>
      <Docs>
        <param name="endpoint"> Service host. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <summary> Initializes a new instance of EmbeddingsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public EmbeddingsClient (Uri endpoint, Azure.Core.TokenCredential credential);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.Core.TokenCredential credential) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.Core.TokenCredential)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As TokenCredential)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.EmbeddingsClient : Uri * Azure.Core.TokenCredential -&gt; Azure.AI.Inference.EmbeddingsClient" Usage="new Azure.AI.Inference.EmbeddingsClient (endpoint, credential)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.Core.TokenCredential" />
      </Parameters>
      <Docs>
        <param name="endpoint"> Service host. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <summary> Initializes a new instance of EmbeddingsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public EmbeddingsClient (Uri endpoint, Azure.AzureKeyCredential credential, Azure.AI.Inference.AzureAIInferenceClientOptions options);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.AzureKeyCredential credential, class Azure.AI.Inference.AzureAIInferenceClientOptions options) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.AzureKeyCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As AzureKeyCredential, options As AzureAIInferenceClientOptions)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.EmbeddingsClient : Uri * Azure.AzureKeyCredential * Azure.AI.Inference.AzureAIInferenceClientOptions -&gt; Azure.AI.Inference.EmbeddingsClient" Usage="new Azure.AI.Inference.EmbeddingsClient (endpoint, credential, options)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.AzureKeyCredential" />
        <Parameter Name="options" Type="Azure.AI.Inference.AzureAIInferenceClientOptions" />
      </Parameters>
      <Docs>
        <param name="endpoint"> The <see cref="T:System.Uri" /> to use. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <param name="options"> The options for configuring the client. </param>
        <summary> Initializes a new instance of EmbeddingsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public EmbeddingsClient (Uri endpoint, Azure.Core.TokenCredential credential, Azure.AI.Inference.AzureAIInferenceClientOptions options);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.Core.TokenCredential credential, class Azure.AI.Inference.AzureAIInferenceClientOptions options) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.Core.TokenCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As TokenCredential, options As AzureAIInferenceClientOptions)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.EmbeddingsClient : Uri * Azure.Core.TokenCredential * Azure.AI.Inference.AzureAIInferenceClientOptions -&gt; Azure.AI.Inference.EmbeddingsClient" Usage="new Azure.AI.Inference.EmbeddingsClient (endpoint, credential, options)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.Core.TokenCredential" />
        <Parameter Name="options" Type="Azure.AI.Inference.AzureAIInferenceClientOptions" />
      </Parameters>
      <Docs>
        <param name="endpoint"> Service host. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <param name="options"> The options for configuring the client. </param>
        <summary> Initializes a new instance of EmbeddingsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName="Embed">
      <MemberSignature Language="C#" Value="public virtual Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt; Embed (Azure.AI.Inference.EmbeddingsOptions embeddingsOptions, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response`1&lt;class Azure.AI.Inference.EmbeddingsResult&gt; Embed(class Azure.AI.Inference.EmbeddingsOptions embeddingsOptions, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.Embed(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function Embed (embeddingsOptions As EmbeddingsOptions, Optional cancellationToken As CancellationToken = Nothing) As Response(Of EmbeddingsResult)" />
      <MemberSignature Language="F#" Value="abstract member Embed : Azure.AI.Inference.EmbeddingsOptions * System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;&#xA;override this.Embed : Azure.AI.Inference.EmbeddingsOptions * System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;" Usage="embeddingsClient.Embed (embeddingsOptions, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="embeddingsOptions" Type="Azure.AI.Inference.EmbeddingsOptions" />
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="embeddingsOptions" />
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="embeddingsOptions" /> is null. </exception>
        <example>
This sample shows how to call Embed.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = client.Embed(embeddingsOptions);
]]></code>
This sample shows how to call Embed.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = client.Embed(embeddingsOptions);
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="Embed">
      <MemberSignature Language="C#" Value="public virtual Azure.Response Embed (Azure.Core.RequestContent content, string extraParams = default, Azure.RequestContext context = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response Embed(class Azure.Core.RequestContent content, string extraParams, class Azure.RequestContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.Embed(Azure.Core.RequestContent,System.String,Azure.RequestContext)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function Embed (content As RequestContent, Optional extraParams As String = Nothing, Optional context As RequestContext = Nothing) As Response" />
      <MemberSignature Language="F#" Value="abstract member Embed : Azure.Core.RequestContent * string * Azure.RequestContext -&gt; Azure.Response&#xA;override this.Embed : Azure.Core.RequestContent * string * Azure.RequestContext -&gt; Azure.Response" Usage="embeddingsClient.Embed (content, extraParams, context)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="content" Type="Azure.Core.RequestContent" />
        <Parameter Name="extraParams" Type="System.String" />
        <Parameter Name="context" Type="Azure.RequestContext" />
      </Parameters>
      <Docs>
        <param name="content"> The content to send as the body of the request. </param>
        <param name="extraParams">
            Controls what happens if extra parameters, undefined by the REST API,
            are passed in the JSON request payload.
            This sets the HTTP request header `extra-parameters`. Allowed values: "error" | "drop" | "pass-through"
            </param>
        <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        <summary>
            [Protocol Method] Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            <list type="bullet"><item><description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description></item><item><description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.Embed(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description></item></list></summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="content" /> is null. </exception>
        <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
      </Docs>
    </Member>
    <Member MemberName="EmbedAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;&gt; EmbedAsync (Azure.AI.Inference.EmbeddingsOptions embeddingsOptions, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response`1&lt;class Azure.AI.Inference.EmbeddingsResult&gt;&gt; EmbedAsync(class Azure.AI.Inference.EmbeddingsOptions embeddingsOptions, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.EmbedAsync(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function EmbedAsync (embeddingsOptions As EmbeddingsOptions, Optional cancellationToken As CancellationToken = Nothing) As Task(Of Response(Of EmbeddingsResult))" />
      <MemberSignature Language="F#" Value="abstract member EmbedAsync : Azure.AI.Inference.EmbeddingsOptions * System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;&gt;&#xA;override this.EmbedAsync : Azure.AI.Inference.EmbeddingsOptions * System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;&gt;" Usage="embeddingsClient.EmbedAsync (embeddingsOptions, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.EmbeddingsResult&gt;&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="embeddingsOptions" Type="Azure.AI.Inference.EmbeddingsOptions" />
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="embeddingsOptions" />
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="embeddingsOptions" /> is null. </exception>
        <example>
This sample shows how to call EmbedAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = await client.EmbedAsync(embeddingsOptions);
]]></code>
This sample shows how to call EmbedAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = await client.EmbedAsync(embeddingsOptions);
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="EmbedAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&gt; EmbedAsync (Azure.Core.RequestContent content, string extraParams = default, Azure.RequestContext context = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response&gt; EmbedAsync(class Azure.Core.RequestContent content, string extraParams, class Azure.RequestContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.EmbedAsync(Azure.Core.RequestContent,System.String,Azure.RequestContext)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function EmbedAsync (content As RequestContent, Optional extraParams As String = Nothing, Optional context As RequestContext = Nothing) As Task(Of Response)" />
      <MemberSignature Language="F#" Value="abstract member EmbedAsync : Azure.Core.RequestContent * string * Azure.RequestContext -&gt; System.Threading.Tasks.Task&lt;Azure.Response&gt;&#xA;override this.EmbedAsync : Azure.Core.RequestContent * string * Azure.RequestContext -&gt; System.Threading.Tasks.Task&lt;Azure.Response&gt;" Usage="embeddingsClient.EmbedAsync (content, extraParams, context)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="content" Type="Azure.Core.RequestContent" />
        <Parameter Name="extraParams" Type="System.String" />
        <Parameter Name="context" Type="Azure.RequestContext" />
      </Parameters>
      <Docs>
        <param name="content"> The content to send as the body of the request. </param>
        <param name="extraParams">
            Controls what happens if extra parameters, undefined by the REST API,
            are passed in the JSON request payload.
            This sets the HTTP request header `extra-parameters`. Allowed values: "error" | "drop" | "pass-through"
            </param>
        <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        <summary>
            [Protocol Method] Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            <list type="bullet"><item><description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description></item><item><description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.EmbedAsync(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description></item></list></summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="content" /> is null. </exception>
        <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfo">
      <MemberSignature Language="C#" Value="public virtual Azure.Response GetModelInfo (Azure.RequestContext context);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response GetModelInfo(class Azure.RequestContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfo(Azure.RequestContext)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfo (context As RequestContext) As Response" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfo : Azure.RequestContext -&gt; Azure.Response&#xA;override this.GetModelInfo : Azure.RequestContext -&gt; Azure.Response" Usage="embeddingsClient.GetModelInfo context" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="context" Type="Azure.RequestContext" />
      </Parameters>
      <Docs>
        <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet"><item><description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description></item><item><description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfo(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description></item></list></summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
        <example>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfo">
      <MemberSignature Language="C#" Value="public virtual Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt; GetModelInfo (System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response`1&lt;class Azure.AI.Inference.ModelInfo&gt; GetModelInfo(valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfo(System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfo (Optional cancellationToken As CancellationToken = Nothing) As Response(Of ModelInfo)" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfo : System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&#xA;override this.GetModelInfo : System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;" Usage="embeddingsClient.GetModelInfo cancellationToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <example>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfoAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&gt; GetModelInfoAsync (Azure.RequestContext context);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response&gt; GetModelInfoAsync(class Azure.RequestContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfoAsync(Azure.RequestContext)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfoAsync (context As RequestContext) As Task(Of Response)" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfoAsync : Azure.RequestContext -&gt; System.Threading.Tasks.Task&lt;Azure.Response&gt;&#xA;override this.GetModelInfoAsync : Azure.RequestContext -&gt; System.Threading.Tasks.Task&lt;Azure.Response&gt;" Usage="embeddingsClient.GetModelInfoAsync context" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="context" Type="Azure.RequestContext" />
      </Parameters>
      <Docs>
        <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet"><item><description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description></item><item><description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfoAsync(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description></item></list></summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
        <example>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfoAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt; GetModelInfoAsync (System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response`1&lt;class Azure.AI.Inference.ModelInfo&gt;&gt; GetModelInfoAsync(valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfoAsync(System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfoAsync (Optional cancellationToken As CancellationToken = Nothing) As Task(Of Response(Of ModelInfo))" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfoAsync : System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt;&#xA;override this.GetModelInfoAsync : System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt;" Usage="embeddingsClient.GetModelInfoAsync cancellationToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <example>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="Pipeline">
      <MemberSignature Language="C#" Value="public virtual Azure.Core.Pipeline.HttpPipeline Pipeline { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Azure.Core.Pipeline.HttpPipeline Pipeline" />
      <MemberSignature Language="DocId" Value="P:Azure.AI.Inference.EmbeddingsClient.Pipeline" />
      <MemberSignature Language="VB.NET" Value="Public Overridable ReadOnly Property Pipeline As HttpPipeline" />
      <MemberSignature Language="F#" Value="member this.Pipeline : Azure.Core.Pipeline.HttpPipeline" Usage="Azure.AI.Inference.EmbeddingsClient.Pipeline" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Core.Pipeline.HttpPipeline</ReturnType>
      </ReturnValue>
      <Docs>
        <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
