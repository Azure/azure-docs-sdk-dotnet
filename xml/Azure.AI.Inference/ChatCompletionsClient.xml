<Type Name="ChatCompletionsClient" FullName="Azure.AI.Inference.ChatCompletionsClient">
  <TypeSignature Language="C#" Value="public class ChatCompletionsClient" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit ChatCompletionsClient extends System.Object" />
  <TypeSignature Language="DocId" Value="T:Azure.AI.Inference.ChatCompletionsClient" />
  <TypeSignature Language="VB.NET" Value="Public Class ChatCompletionsClient" />
  <TypeSignature Language="F#" Value="type ChatCompletionsClient = class" />
  <AssemblyInfo>
    <AssemblyName>Azure.AI.Inference</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary> The ChatCompletions service client. </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="protected ChatCompletionsClient ();" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.#ctor" />
      <MemberSignature Language="VB.NET" Value="Protected Sub New ()" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary> Initializes a new instance of ChatCompletionsClient for mocking. </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public ChatCompletionsClient (Uri endpoint, Azure.AzureKeyCredential credential);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.AzureKeyCredential credential) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.AzureKeyCredential)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As AzureKeyCredential)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.ChatCompletionsClient : Uri * Azure.AzureKeyCredential -&gt; Azure.AI.Inference.ChatCompletionsClient" Usage="new Azure.AI.Inference.ChatCompletionsClient (endpoint, credential)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.AzureKeyCredential" />
      </Parameters>
      <Docs>
        <param name="endpoint"> Service host. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <summary> Initializes a new instance of ChatCompletionsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public ChatCompletionsClient (Uri endpoint, Azure.Core.TokenCredential credential);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.Core.TokenCredential credential) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.Core.TokenCredential)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As TokenCredential)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.ChatCompletionsClient : Uri * Azure.Core.TokenCredential -&gt; Azure.AI.Inference.ChatCompletionsClient" Usage="new Azure.AI.Inference.ChatCompletionsClient (endpoint, credential)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.Core.TokenCredential" />
      </Parameters>
      <Docs>
        <param name="endpoint"> Service host. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <summary> Initializes a new instance of ChatCompletionsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public ChatCompletionsClient (Uri endpoint, Azure.AzureKeyCredential credential, Azure.AI.Inference.AzureAIInferenceClientOptions options);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.AzureKeyCredential credential, class Azure.AI.Inference.AzureAIInferenceClientOptions options) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.AzureKeyCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As AzureKeyCredential, options As AzureAIInferenceClientOptions)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.ChatCompletionsClient : Uri * Azure.AzureKeyCredential * Azure.AI.Inference.AzureAIInferenceClientOptions -&gt; Azure.AI.Inference.ChatCompletionsClient" Usage="new Azure.AI.Inference.ChatCompletionsClient (endpoint, credential, options)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.AzureKeyCredential" />
        <Parameter Name="options" Type="Azure.AI.Inference.AzureAIInferenceClientOptions" />
      </Parameters>
      <Docs>
        <param name="endpoint"> The <see cref="T:System.Uri" /> to use. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <param name="options"> The options for configuring the client. </param>
        <summary> Initializes a new instance of ChatCompletionsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public ChatCompletionsClient (Uri endpoint, Azure.Core.TokenCredential credential, Azure.AI.Inference.AzureAIInferenceClientOptions options);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Uri endpoint, class Azure.Core.TokenCredential credential, class Azure.AI.Inference.AzureAIInferenceClientOptions options) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.Core.TokenCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (endpoint As Uri, credential As TokenCredential, options As AzureAIInferenceClientOptions)" />
      <MemberSignature Language="F#" Value="new Azure.AI.Inference.ChatCompletionsClient : Uri * Azure.Core.TokenCredential * Azure.AI.Inference.AzureAIInferenceClientOptions -&gt; Azure.AI.Inference.ChatCompletionsClient" Usage="new Azure.AI.Inference.ChatCompletionsClient (endpoint, credential, options)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="endpoint" Type="System.Uri" />
        <Parameter Name="credential" Type="Azure.Core.TokenCredential" />
        <Parameter Name="options" Type="Azure.AI.Inference.AzureAIInferenceClientOptions" />
      </Parameters>
      <Docs>
        <param name="endpoint"> Service host. </param>
        <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        <param name="options"> The options for configuring the client. </param>
        <summary> Initializes a new instance of ChatCompletionsClient. </summary>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName="Complete">
      <MemberSignature Language="C#" Value="public virtual Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt; Complete (Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response`1&lt;class Azure.AI.Inference.ChatCompletions&gt; Complete(class Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.Complete(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function Complete (chatCompletionsOptions As ChatCompletionsOptions, Optional cancellationToken As CancellationToken = Nothing) As Response(Of ChatCompletions)" />
      <MemberSignature Language="F#" Value="abstract member Complete : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;&#xA;override this.Complete : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;" Usage="chatCompletionsClient.Complete (chatCompletionsOptions, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="chatCompletionsOptions" Type="Azure.AI.Inference.ChatCompletionsOptions" />
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="chatCompletionsOptions">
            The configuration information for a chat completions request.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </param>
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Gets chat completions for the provided chat messages.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data. The method makes a REST API call to the `/chat/completions` route
            on the given endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="chatCompletionsOptions" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName="CompleteAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;&gt; CompleteAsync (Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response`1&lt;class Azure.AI.Inference.ChatCompletions&gt;&gt; CompleteAsync(class Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.CompleteAsync(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function CompleteAsync (chatCompletionsOptions As ChatCompletionsOptions, Optional cancellationToken As CancellationToken = Nothing) As Task(Of Response(Of ChatCompletions))" />
      <MemberSignature Language="F#" Value="abstract member CompleteAsync : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;&gt;&#xA;override this.CompleteAsync : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;&gt;" Usage="chatCompletionsClient.CompleteAsync (chatCompletionsOptions, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ChatCompletions&gt;&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="chatCompletionsOptions" Type="Azure.AI.Inference.ChatCompletionsOptions" />
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="chatCompletionsOptions">
            The configuration information for a chat completions request.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </param>
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Gets chat completions for the provided chat messages.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data. The method makes a REST API call to the `/chat/completions` route
            on the given endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="chatCompletionsOptions" /> is null. </exception>
      </Docs>
    </Member>
    <Member MemberName="CompleteStreaming">
      <MemberSignature Language="C#" Value="public virtual Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt; CompleteStreaming (Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.AI.Inference.StreamingResponse`1&lt;class Azure.AI.Inference.StreamingChatCompletionsUpdate&gt; CompleteStreaming(class Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.CompleteStreaming(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function CompleteStreaming (chatCompletionsOptions As ChatCompletionsOptions, Optional cancellationToken As CancellationToken = Nothing) As StreamingResponse(Of StreamingChatCompletionsUpdate)" />
      <MemberSignature Language="F#" Value="abstract member CompleteStreaming : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;&#xA;override this.CompleteStreaming : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;" Usage="chatCompletionsClient.CompleteStreaming (chatCompletionsOptions, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="chatCompletionsOptions" Type="Azure.AI.Inference.ChatCompletionsOptions" />
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="chatCompletionsOptions">
                the chat completions options for this chat completions request.
            </param>
        <param name="cancellationToken">
                a cancellation token that can be used to cancel the initial request or ongoing streaming operation.
            </param>
        <summary>
                Begin a chat completions request and get an object that can stream response data as it becomes
                available.
            </summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="chatCompletionsOptions" /> or <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is null.
            </exception>
        <exception cref="T:System.ArgumentException">
          <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is an empty string.
            </exception>
      </Docs>
    </Member>
    <Member MemberName="CompleteStreamingAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;&gt; CompleteStreamingAsync (Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.AI.Inference.StreamingResponse`1&lt;class Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;&gt; CompleteStreamingAsync(class Azure.AI.Inference.ChatCompletionsOptions chatCompletionsOptions, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.CompleteStreamingAsync(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function CompleteStreamingAsync (chatCompletionsOptions As ChatCompletionsOptions, Optional cancellationToken As CancellationToken = Nothing) As Task(Of StreamingResponse(Of StreamingChatCompletionsUpdate))" />
      <MemberSignature Language="F#" Value="abstract member CompleteStreamingAsync : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;&gt;&#xA;override this.CompleteStreamingAsync : Azure.AI.Inference.ChatCompletionsOptions * System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;&gt;" Usage="chatCompletionsClient.CompleteStreamingAsync (chatCompletionsOptions, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.AI.Inference.StreamingResponse&lt;Azure.AI.Inference.StreamingChatCompletionsUpdate&gt;&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="chatCompletionsOptions" Type="Azure.AI.Inference.ChatCompletionsOptions" />
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="chatCompletionsOptions">
                the chat completions options for this chat completions request.
            </param>
        <param name="cancellationToken">
                a cancellation token that can be used to cancel the initial request or ongoing streaming operation.
            </param>
        <summary>
                Begin a chat completions request and get an object that can stream response data as it becomes
                available.
            </summary>
        <returns>
            A response that, if the request was successful, may be asynchronously enumerated for
            <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" /> instances.
            </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:System.ArgumentNullException">
          <paramref name="chatCompletionsOptions" /> or <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is null.
            </exception>
        <exception cref="T:System.ArgumentException">
          <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is an empty string.
            </exception>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfo">
      <MemberSignature Language="C#" Value="public virtual Azure.Response GetModelInfo (Azure.RequestContext context);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response GetModelInfo(class Azure.RequestContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfo(Azure.RequestContext)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfo (context As RequestContext) As Response" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfo : Azure.RequestContext -&gt; Azure.Response&#xA;override this.GetModelInfo : Azure.RequestContext -&gt; Azure.Response" Usage="chatCompletionsClient.GetModelInfo context" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="context" Type="Azure.RequestContext" />
      </Parameters>
      <Docs>
        <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet"><item><description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description></item><item><description>
            Please try the simpler <see cref="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfo(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description></item></list></summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
        <example>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfo">
      <MemberSignature Language="C#" Value="public virtual Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt; GetModelInfo (System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Azure.Response`1&lt;class Azure.AI.Inference.ModelInfo&gt; GetModelInfo(valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfo(System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfo (Optional cancellationToken As CancellationToken = Nothing) As Response(Of ModelInfo)" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfo : System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&#xA;override this.GetModelInfo : System.Threading.CancellationToken -&gt; Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;" Usage="chatCompletionsClient.GetModelInfo cancellationToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <example>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfoAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&gt; GetModelInfoAsync (Azure.RequestContext context);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response&gt; GetModelInfoAsync(class Azure.RequestContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfoAsync(Azure.RequestContext)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfoAsync (context As RequestContext) As Task(Of Response)" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfoAsync : Azure.RequestContext -&gt; System.Threading.Tasks.Task&lt;Azure.Response&gt;&#xA;override this.GetModelInfoAsync : Azure.RequestContext -&gt; System.Threading.Tasks.Task&lt;Azure.Response&gt;" Usage="chatCompletionsClient.GetModelInfoAsync context" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="context" Type="Azure.RequestContext" />
      </Parameters>
      <Docs>
        <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet"><item><description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description></item><item><description>
            Please try the simpler <see cref="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfoAsync(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description></item></list></summary>
        <returns> The response returned from the service. </returns>
        <remarks>To be added.</remarks>
        <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
        <example>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="GetModelInfoAsync">
      <MemberSignature Language="C#" Value="public virtual System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt; GetModelInfoAsync (System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class System.Threading.Tasks.Task`1&lt;class Azure.Response`1&lt;class Azure.AI.Inference.ModelInfo&gt;&gt; GetModelInfoAsync(valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfoAsync(System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overridable Function GetModelInfoAsync (Optional cancellationToken As CancellationToken = Nothing) As Task(Of Response(Of ModelInfo))" />
      <MemberSignature Language="F#" Value="abstract member GetModelInfoAsync : System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt;&#xA;override this.GetModelInfoAsync : System.Threading.CancellationToken -&gt; System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt;" Usage="chatCompletionsClient.GetModelInfoAsync cancellationToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.Task&lt;Azure.Response&lt;Azure.AI.Inference.ModelInfo&gt;&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="cancellationToken"> The cancellation token to use. </param>
        <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <example>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code></example>
      </Docs>
    </Member>
    <Member MemberName="Pipeline">
      <MemberSignature Language="C#" Value="public virtual Azure.Core.Pipeline.HttpPipeline Pipeline { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Azure.Core.Pipeline.HttpPipeline Pipeline" />
      <MemberSignature Language="DocId" Value="P:Azure.AI.Inference.ChatCompletionsClient.Pipeline" />
      <MemberSignature Language="VB.NET" Value="Public Overridable ReadOnly Property Pipeline As HttpPipeline" />
      <MemberSignature Language="F#" Value="member this.Pipeline : Azure.Core.Pipeline.HttpPipeline" Usage="Azure.AI.Inference.ChatCompletionsClient.Pipeline" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.Inference</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.Core.Pipeline.HttpPipeline</ReturnType>
      </ReturnValue>
      <Docs>
        <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
